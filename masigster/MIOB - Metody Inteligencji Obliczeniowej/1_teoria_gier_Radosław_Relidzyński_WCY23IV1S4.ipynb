{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1i-CotF3UfptC_aNESbgaTD0sH8Wnog_r","timestamp":1742281359642}],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Zasady\n","\n","1. Medium komunikacji: MS Teams. Rozliczanie zadań: e-learning.\n","2. Aby zaliczyć dane laboratorium, należy załączyć na e-learningu:\n","  - plik `.ipynb` z rozwiązaniem oraz link do Boogle Colab w komentarzu do pliku Notebooka.\n","  - proszę nadać uprawnienia do podglądu pliku na Google Colab (*Anyone with link: viewer*)\n","  - plik oraz link należy wysłać do ustalonego dnia i godziny\n","  - jeżeli student wie z wyprzedzeniem, że nie będzie z przyczyn niezależnych mógł wykonać zadania na czas, należy to zgłosić prowadzącemu najpóźniej 3 dni przed zaplanowanym czasem oddania zadania\n","  - rozwiązania zadań należy wpisywać w komórkach zawierających \"**Odpowiedź**\"\n","  - **Uwaga: wszystkie zadania z notebooka muszą być wypełnione aby zaliczyć dane laboratorium!**\n","3. Do rozwiązywania zadań **należy** w celach edukacyjnych korzystać z Asystentów AI takich jak:\n","  - [Grok 3](grok.com) - można korzystać za darmo\n","  - ChatGPT - model 4o powinien być wystarczający\n","  - [Google AI Studio](https://aistudio.google.com/) - również w opcji darmowej pozwala na korzystanie z różnych zaawansowanych modeli.\n","  - Powyższe Chatboty pozwalają na rozwiewanie wątpliwości, tłumaczenie skomplikowanych konceptów, wyjaśnianie formuł matematycznych, generowanie przykładów obliczeniowych, generowanie kodów etc. Odpowiednie ich wykorzystanie znacząco pomoże w zrozumieniu materiału.\n","4. W razie uwag, problemów, pomysłów co do formuły zajęć proszę wpisywać je pod tym linkiem: https://forms.gle/pSRp4pYbYdxhkoU26.\n","\n","*Wskazówka 1*: zadawanie pytań po angielsku często daje lepsze wyniki niż po polsku.\n","\n","*Wskazówka 2*: jeżeli podczas próby zrozumienia materiału pojawi się w głowie **dowolna** wątpliwość, należy od razu zapytać AI w celu jej wyjaśnienia.\n","\n","*Wskazówka 3*: często wystarczy wkleić screenshot'a z definicją, formułą matematyczną aby uzyskać jej wytłumaczenie.\n","\n","*Wskazówka 4*: warto zapytań o potwierdzenie rozumienia, np. *Czy mogę powiedzieć, że gry w postaci normalnej w kontekście podejmowania decyzji przez wielu agentów są najprostszym przypadkiem, gdy mamy do czynienia z jednorundowymi sytuacjami o zdefiniowanych nagrodach i musimy znaleźć najlepszą wspólną decyzję, zarówno wtedy, gdy agenci zwracają na siebie uwagę (równowaga Nasha), jak i wtedy, gdy tego nie robią (równowaga dominująca)?*\n","\n","\n","\n"],"metadata":{"id":"XBea0QSduij8"}},{"cell_type":"markdown","source":["# Plan Kursu\n","\n","\n","W **Wieloagentowym Podejmowaniu Decyzji (ang. Multiagent Decision Making, MADM)** badamy, w jaki sposób wiele autonomicznych agentów (np. roboty, oprogramowanie, czy ludzie) podejmują decyzje w środowiskach, w których ich działania wzajemnie na siebie oddziałują. Rozdział V książki *Algorithms for Decision Making* (Sekcje 24–27) oferuje wszechstronne wprowadzenie do MADM, prezentując kluczowe koncepcje i algorytmy w czterech głównych obszarach.\n","\n","Sekcje te wzajemnie się uzupełniają:\n","- **Sekcja 24** – wprowadza podstawy strategii i rozumowania agentów.\n","- **Sekcja 25** – rozbudowuje je o podejmowanie decyzji w czasie.\n","- **Sekcja 26** – uwzględnia niepewność dotyczącą stanu środowiska.\n","- **Sekcja 27** – skupia się na współpracy agentów w celu osiągnięcia wspólnego celu.\n","\n","\n","### **Sekcja 24: Wieloagentowe Rozumowanie**  \n","- Ta sekcja stanowi fundament teorii gier w kontekście systemów wieloagentowych. Wprowadza, jak agenci przewidują i uwzględniają działania innych w warunkach strategicznych, wykorzystując pojęcia takie jak **Równowaga Nasha** (sytuacja, w której żaden agent nie może poprawić swojego wyniku, zmieniając jednostronnie strategię przy założeniu, że inni tego nie czynią) czy **Strategia Dominująca**.\n","- **Rola w MADM**: Wieloagentowe Rozumowanie dostarcza narzędzi do modelowania i przewidywania wyników w sytuacjach, w których decyzje agentów są współzależne. Stanowi punkt wyjścia do badania zjawisk konkurencji czy negocjacji.\n","\n","\n","### **Sekcja 25: Problemy Sekwencyjne**  \n","- Decyzje w świecie rzeczywistym często podejmuje się wielokrotnie, nie tylko raz. W tej sekcji wprowadza się **Gry Markowa (Markov Games)**, które opisują dynamiczne scenariusze, gdzie działania agentów wpływają na stan środowiska, a więc i na przyszłe decyzje. Opierając się na Równowadze Nasha, wprowadza się również metody takie jak **Nash Q-Learning**, by agenci mogli się uczyć strategii przez doświadczenie w zmieniających się warunkach.\n","- **Rola w MADM**: Problemy Sekwencyjne dotyczą dynamiki w systemach wieloagentowych, gdzie agenci muszą planować w czasie i dostosowywać się do zmian. Jest to kluczowe w środowiskach, w których ważna jest kolejność i czas działań, np. w robotyce czy logistyce.\n","\n","\n","### **Sekcja 26: Niepewność Stanu**  \n","- W praktyce agenci rzadko dysponują pełną wiedzą o środowisku. Ta sekcja przedstawia **Częściowo Obserwowalne Gry Markowa (POMGs)**, gdzie agenci podejmują decyzje na podstawie niepełnych informacji (np. danych z czujników, a nie pełnej obserwacji). Omawia się też **Ocenę Polityki (Policy Evaluation)**, Równowagę Nasha w warunkach niepewności i metody **Programowania Dynamicznego** (Dynamic Programming) do obliczania rozwiązań. Wszystko to jest niezbędne, by radzić sobie z rzeczywistymi wyzwaniami.\n","- **Rola w MADM**: Niepewność Stanu odnosi się do kluczowego problemu w systemach wieloagentowych: skutecznego działania pomimo niepełnych informacji. To istotne w zastosowaniach, w których dostępność danych jest ograniczona (np. nawigacja autonomiczna czy bezpieczeństwo).\n","\n","\n","### **Sekcja 27: Współpraca Agentów**  \n","- Nie wszystkie scenariusze wieloagentowe sprowadzają się do konkurencji—często agenci muszą współpracować. Ta sekcja skupia się na **Zdecentralizowanych Częściowo Obserwowalnych Procesach Decyzyjnych (Dec-POMDPs)**, które opisują kooperację w warunkach niepewności i ograniczonej komunikacji. Wykorzystuje się m.in. **Programowanie Dynamiczne**, **Iterated Best Response**, **Heurystyczne Przeszukiwanie (Heuristic Search)** i **Programowanie Nieliniowe (Nonlinear Programming)**, aby zgrać działania agentów wokół wspólnego celu.\n","- **Rola w MADM**: Współpraca Agentów jest kluczowa tam, gdzie agenci dzielą te same cele, np. w sytuacjach ratowniczych czy przy zarządzaniu infrastrukturą. Przedstawione metody uczą koordynacji w trudnych warunkach.\n","\n","### Technologie\n","- Python\n","- Google Colab / Jupiter Notebook\n","- [Petting Zoo](https://pettingzoo.farama.org/index.html)\n"],"metadata":{"id":"Knom6nm1EnGj"}},{"cell_type":"markdown","source":["# Wprowadzenie do Teorii Gier"],"metadata":{"id":"m-4mOnAbd5qO"}},{"cell_type":"markdown","source":["## Bibliografia\n","\n","[\"Algorithms for Decision Making\", Mykel J. Kochenderfer, Tim A. Wheeler, and Kyle H. Wray, MIT Press, 2022](https://algorithmsbook.com/files/dm.pdf)\n","  * Część V, Sekcja 24: 1, 3, 4\n","  * Dodatek F.10, F.11"],"metadata":{"id":"65eGCbs5ostk"}},{"cell_type":"markdown","source":["## Sekcja 24.1 Proste Gry\n","\n","*W systemach wieloagentowych często agenci muszą podejmować decyzje, nie znając dokładnie wyborów innych, choć ich wyniki zależą od wspólnych działań. Gry w formie normalnej (tzw. macierz wypłat) dają przejrzyste ramy do modelowania takich interakcji—czy to negocjacje między robotami dzielącymi zasoby, czy firmy konkurujące na rynku.*"],"metadata":{"id":"xZxX0QIXa9io"}},{"cell_type":"markdown","source":["### Zadanie 1\n","**Pytanie**: Wyjaśnij własnymi słowami, na czym polega problem Dylematu Więźnia."],"metadata":{"id":"Qd9O9QBcj4Fv"}},{"cell_type":"markdown","source":["**Odpowiedź**: Dylemat więźnia opiera się o sytuację, kiedy dwie osoby są niezależnie przesłuchiwane i mogą albo milczeć albo zeznawać przeciwko drugiej osobie. Każda kombinacja podjętej dezycji przez każdego więźnia ma pewien określony rezultat."],"metadata":{"id":"QxLSxQeij98y"}},{"cell_type":"markdown","source":["### Zadanie 2\n","**Pytanie**: W oparciu o pojęcie „Prostej Gry” zdefiniuj Dylemat Więźnia."],"metadata":{"id":"d1rdMYxSj-c2"}},{"cell_type":"markdown","source":["**Odpowiedź**: Jest to \"Prosta Gra\", ponieważ jest dwóch graczy, niewielki zbiór strategii oraz rezultat, który zależy od kombinacji strategii dla graczy.\n","\n","Definicja:\n","- Dwóch graczy: Więzień W1, Więzień W2\n","- Dwie strategie: M - milczenie, Z - zeznawanie\n","- Możliwe rezultaty:\n","  1. Zdrada (W1:M, W2:Z lub W1:Z, W2:M)\n","  2. Współpraca (W1:M, W2:M)\n","  3. Wzajemna zdrada (W1:Z, W2:Z)\n","- Możliwe kary dla więźniów:\n","  1. T - przy jednostronnym zdradzeniu współwięźnia\n","  2. R - przy obustronnym milczeniu\n","  3. P - przy wzajemnej zdradzie\n","  4. S - przy jednostronnym zostaniu zdradzonym\n","  - Zależność między nimi: T > R > P > S\n","  - Często też 2R > T + S (wzmacnia nieopłacalność wzajemnej zdrady)\n","\n","Tabela przedstawia wszystkie możliwe Rezultaty:\n","\\begin{array}{c|cc} &\n","\\text{W2: M} & \\text{W2: Z} \\\\\n","\\hline\n","\\text{W1: M} & (R, R) & (S, T) \\\\\n","\\text{W1: Z} & (T, S) & (P, P) \\\\\n","\\end{array}\n","\n","- Strategia dominująca w przypadku tej gry to Z - zaznawanie (daje indywidualnie lepszy wynik).\n","- Równowaga Nasha występuje w punkcie (W1:Z, W2:Z) - w tym przypadku żaden więzień nie zdecyduje się do jednostronnej zmiany decyzji.\n","- Paradoks dylematu - najlepszy wynik gry jest w punkcie (W1:M, W2:M), natomiast jest to nieoptymalne indywidualnie, bo nadal można zmienić decyzję, czym w takiej sytuacji można wygrać kosztem gorszej kary drugiego."],"metadata":{"id":"9mayeym_kDSR"}},{"cell_type":"markdown","source":["### Zadanie 3\n","**Pytanie**: Dla Dylematu Więźnia zdefiniuj:\n","- Przestrzeń działań wspólnych (joint action space).\n","- Wspólną funkcję nagrody (joint reward function)."],"metadata":{"id":"fEuiMoi7kFeL"}},{"cell_type":"markdown","source":["**Odpowiedź**:\n","- Przestrzeń działań wspólnych:\n","  - Zbiór możliwych akcji: Ai = {M, Z}\n","  - Przestrzeń działań wspólnych: Pw = Aw1 x Aw2 = {(M, M), (M, Z), (Z, M), (Z, Z)}\n","\n","- Wspólna funkcja nagrody:\n","  - Funkcja wypłaty: ui(a1, a2), gdzie (a1, a2) należy do Pw\n","  - Wspólna funkcja nagrody: Rw(a, b) = uW1(aW1, aW2) + uW2(aW1, aW2)"],"metadata":{"id":"RhmaBDhVkJcY"}},{"cell_type":"markdown","source":["### Zadanie 4\n","**Pytanie**: Jaka jest różnica między „payoff” a „reward” w kontekście Dylematu Więźnia?"],"metadata":{"id":"m_BOQcVMkLOJ"}},{"cell_type":"markdown","source":["**Odpowiedź**:\n","\n","Payoff – każdy możliwy wynik uzyskiwany w grze w zależności od wyboru strategii własnej i przeciwnika.\n","\n","Reward – konkretna wartość przyznawana obu graczom w wypadku, gdy obaj wybrali strategię współpracy\n","\n"],"metadata":{"id":"rzzhGlybkOOK"}},{"cell_type":"markdown","source":["### Zadanie 5\n","**Pytanie**: Korzystając z przykładu Dylematu Więźnia, wyjaśnij różnicę między deterministyczną wspólną polityką (joint policy) a polityką stochastyczną (tzw. mixed policy)."],"metadata":{"id":"vL_BoEc9kPt3"}},{"cell_type":"markdown","source":["**Odpowiedź**:\n","\n","deterministyczna wspólna polityka to taka, w której działania obu graczy są w pełni zdeterminowane (np. zawsze współpracujcie)\n","\n","polityka stochastyczna oznacza, że wybór akcji jest oparty na pewnym rozkładzie prawdopodobieństwa (np. w 70% współpracuj, w 30% zdradzaj)\n","\n","Różnica polega więc na przewidywalności podjęcia decyzji - w deterministycznej jest ona przewidywalna, w stochastycznej nie ze względu na zastosowanie prawdopodobieństwa"],"metadata":{"id":"kPzeXf_IkR4j"}},{"cell_type":"markdown","source":["### Zadanie 6\n","**Pytanie**: Podaj przykład:\n","- Strategii czystej (deterministycznej) dla pojedynczego agenta w Dylemacie Więźnia.\n","- Polityki stochastycznej (strategii mieszanej) dla pojedynczego agenta w Dylemacie Więźnia."],"metadata":{"id":"ZPjp-vj6kTTk"}},{"cell_type":"markdown","source":["**Odpowiedź**:\n","\n","Przykład strategii czystej: W kazdej rundzie zdradzaj\n","\n","Przykład polityki stochastycznej: W każdej rundzie współpracuj z prawdopodobieństwem 70%, a zdradzaj z prawdopodobieństwem 30%\n"],"metadata":{"id":"XdU0eztOkUns"}},{"cell_type":"markdown","source":["### Zadanie 7\n","**Pytanie**: Wyjaśnij użyteczność (utility) wspólnej polityki π w Dylemacie Więźnia, wykorzystując przykład konkretnej strategii mieszanej."],"metadata":{"id":"-TRw5kNmkdgo"}},{"cell_type":"markdown","source":["**Odpowiedź**:\n","\n","W teorii gier „użyteczność” danej polityki to oczekiwany zysk gracza wynikający ze stosowania tej polityki. W przypadku wspólnej polityki mówimy o tym, jak obaj gracze wybierają swoje działania, a każdemu z nich można przypisać oczekiwaną użyteczność w zależności od tej wspólnej polityki.\n","\n","**Przykładowa strategia do zastosowania:**\n","W każdej rundzie współpracuj z prawdopodobieństwem 70%, a zdradzaj z prawdopodobieństwem 30%\n","\n","Wykorzystując poprzednie oznaczenia:\n","\n","\\begin{array}{c|cc} &\n","\\text{W2: M} & \\text{W2: Z} \\\\\n","\\hline\n","\\text{W1: M} & (R, R) & (S, T) \\\\\n","\\text{W1: Z} & (T, S) & (P, P) \\\\\n","\\end{array}\n","\n","Uzyteczność obliczana by była dla każdego przypadku:\n","P(R, R), P(S, T), P(T, S), P(P, P)\n","\n","Obliczenie prawodpodobieństw:\n","* P(R, R) = 0.7 * 0.7 = 0.49\n","* P(S, T) = 0.7 * 0.3 = 0.21\n","* P(T, S) = 0.3 * 0.7 = 0.21\n","* P(P, P) = 0.3 * 0.3 = 0.09\n","\n","**Obliczanie użyteczności:**\n","\n","Będzie to suma iloczynów każdego prawdopodobieństwa z wartością, która temu przysługuje.\n","\n","Na rzecz obliczeń przyjmujmy, że:\n","**T=5, R=3, P=1, S=0**.\n","\n","Zatem tak zostanie obliczona użyteczność:\n","\n","P(R, R) * R + P(S, T) * S + P(T, S) * T + P(P, P) * P = 0.49 * 3 + 0.21 * 0 + 0.21 * 5 + 0.09 * 1 = 2.61"],"metadata":{"id":"2_k6SnvGkgUt"}},{"cell_type":"markdown","source":["### Zadanie 8\n","**Pytanie**: Jaki jest sens stosowania użyteczności wspólnej polityki π? Co ona intuicyjnie reprezentuje?"],"metadata":{"id":"uliVDZsSkhf_"}},{"cell_type":"markdown","source":["**Odpowiedź**: Reprezentuje ona skuteczność danej polityki podając oczekiwaną (średnią) wartość jaką daje jej wykorzystanie. Stosując ją dla obu graczy dostajemy wynik, który można następnie porównywać z wynikami takiego samego eksperymentu przeprowadzonego dla innych polityk."],"metadata":{"id":"uAtxw8a9kior"}},{"cell_type":"markdown","source":["## 24.3 Strategia Dominująca\n","*Strategia dominująca to taka, która jest najlepsza dla agenta bez względu na to, co robią inni. Jeśli każdy agent ma strategię dominującą i ją wybiera, otrzymujemy równowagę w strategiach dominujących—wszyscy robią to, co dla nich najlepsze w kontekście gry.\n","Z perspektywy systemów wieloagentowych koncept ten może znacząco uprościć podejmowanie decyzji. Gdyby (hipotetycznie) agent (np. autonomiczny samochód w ruchu drogowym) miał zawsze najlepszą możliwą strategię bez względu na zachowania innych („zawsze przestrzegaj przepisów”), nie musiałby analizować posunięć pozostałych uczestników ruchu. Jednak nie wszystkie sytuacje dopuszczają istnienie strategii dominujących—dlatego potrzebujemy innych metod.*"],"metadata":{"id":"yvKuBtkabBhj"}},{"cell_type":"markdown","source":["### Zadanie 1\n","**Pytanie**: Zdefiniuj „Grę w Cykora” (Chicken Game) i podaj jej macierz wypłat."],"metadata":{"id":"XY__iP3znDjw"}},{"cell_type":"markdown","source":["**Odpowiedź**:\n","\n","Gra w Cykora:\n","\n","Dwóch kierowców jedzie naprzeciw siebie wąską drogą. Każdy z nich ma do wyboru jedną z dwóch akcji:\n","* Zjechać (Swerve) – ustąpić, „uciec” z pasa.\n","* Nie zjechać (Dare) – jechać prosto, licząc na to, że ustąpi przeciwnik.\n","\n","Definicja:\n","* Kierowcy: K1, K2\n","* Decyzje: S - zjechać, D - nie zjeżdżać\n","* Możliwe rezultaty:\n","  * Obaj zjeżdżają (K1:S, K2:S) - brak zderzenia, ale też brak wygranego\n","  * Jeden zjedzie (K1:S, K2:D lub K1:D, K2:S) - brak zdejrzenia, ten, który nie zjedzie, wygrywa\n","  * Obaj nie zdeżdżają, zderzenie (K1:D, K2:D) - obaj przegrywają\n","\n","Możliwe nagrody:\n","1. R - remis, brak zderzenia, brak wygranych\n","2. L - przegrana, zjechanie kiedy drugi gracz nie zjechał\n","3. W - wygrana, nie zjechanie kiedy drugi gracz zjechał\n","4. C - zderzenie, kiedy żaden nie zjedzie\n","* Zależność między nimi: W > R > L > C\n","\n","Tabela przedstawia wszystkie możliwe Rezultaty:\n","\\begin{array}{c|cc} &\n","\\text{K2: S} & \\text{K2: D} \\\\\n","\\hline\n","\\text{K1: S} & (R, R) & (L, W) \\\\\n","\\text{K1: D} & (W, L) & (C, C) \\\\\n","\\end{array}"],"metadata":{"id":"uGc2lSs6neoB"}},{"cell_type":"markdown","source":["### Zadanie 2\n","**Pytanie**: Znajdź strategię dominującą dla Gracza 1 i Gracza 2 w „Grze w Cykora”. Czy istnieje *równowaga w strategiach dominujących (dominant strategy equilirium)*?"],"metadata":{"id":"SrqvwMT1bJv3"}},{"cell_type":"markdown","source":["**Odpowiedź**:\n","\n","W przypadku, gdy drugi gracz wybierze, żeby nie zjechać, lepiej jest zjechać (nagroda L zamiast C)\n","\n","W przypadku, gdy drugi gracz wybierze, żeby zjechać, lepiej jest nie zjeżdżać (nagroda W zamiast R)\n","\n","Stąd, nie ma strategii dominującej w tej grze. W związku z tym nie ma również równowagi w strategiach dominujących."],"metadata":{"id":"4-ZSZjCZnfEX"}},{"cell_type":"markdown","source":["## 24.3 Równowaga Nasha\n","\n","*Równowaga Nasha zachodzi, gdy żaden agent nie może poprawić swojego wyniku, jednostronnie zmieniając strategię, jeśli inni jej nie zmieniają. To tzw. „stan stabilny”, w którym każda decyzja jest najlepszą odpowiedzią (best response) na decyzje pozostałych.*"],"metadata":{"id":"JBm0Pbgso9jW"}},{"cell_type":"markdown","source":["### Zadanie 1\n","**Pytanie**: Znajdź *Równowagę Nasha* w Grze w Cykora. Wyjaśnij różnicę między *równowagą w strategiach dominujących (dominant strategy equilirium)* a *równowagą Nasha* na przykładzie tej gry. Co jest główną różnicą między tymi dwoma podejściami?"],"metadata":{"id":"5rs2NcAapDew"}},{"cell_type":"markdown","source":["**Odpowiedź**:\n","\n","Sprawdzanie kiedy strategie obydwu graczy wzajemnie się „stabilizują” (każdy wybiera najlepszą odpowiedź na strategię przeciwnika):\n","\n","1. (S, S): Gracz może poprawnić swój wynik zmieniając z S na D (Nagroda zmienia się z R na W), nie jest równowagą Nasha.\n","2. (S, D):\n","* Załóżmy, że Gracz 2 wybiera D.\n","  * Gracz 1 porównuje swoje wypłaty:\n","    * S (przeciw D) daje mu L\n","    * D (przeciw D) daje mu C\n","    * Lepiej wybrać S.\n","* Załóżmy, że Gracz 1 wybiera S.\n","  * Gracz 2 porównuje swoje wypłaty:\n","    * S (przeciw S) to R.\n","    * D (przeciw S) to W.\n","    * Lepiej wybrać D.\n","Każdy z graczy nie zmieniając decyzji zachowuje się racjonalnie, więc (S, D) jest równowagą Nasha.\n","3. (D, S): Analogicznie do punktu 2, również jest równowagą nasha\n","4. (D, D): Gracz może poprawnić swój wynik zmieniając z D na S (Nagroda zmienia się z C na L), nie jest równowagą Nasha.\n","\n","Zatem Równowaga Nasha jest wtedy, kiedy gracze wybiorą różne strategie.\n","\n","**Różnica między równowagą w strategiach dominujących (dominant strategy equilirium) a równowagą Nasha.**\n","\n","1. **Równowaga w strategiach dominujących (dominant strategy equilibrium)**  \n","   - Wymaga, aby każdy gracz miał dokładnie jedną strategię, która zawsze jest lepsza niezależnie od tego, co robi przeciwnik.  \n","   - Jeśli obaj gracze takie strategie posiadają i wybiorą je, powstaje równowaga w strategiach dominujących.\n","   - W „Grze w Cykora” żaden z graczy nie ma takiej strategii (patrząc w macierz, widać, że wybór „D” bywa korzystniejszy, jeśli przeciwnik zjeżdża, ale fatalny, jeśli on też wybiera D).\n","\n","2. **Równowaga Nasha**  \n","   - Wymaga tylko”, że jeśli jeden gracz „zakotwiczy się” w danej strategii, to strategia drugiego jest dla niego najlepszą odpowiedzią.  \n","   - Nie oznacza, że któraś ze strategii jest „zawsze najlepsza”; chodzi jedynie o wzajemną stabilność wyborów.  \n","   - W „Grze w Cykora” widzimy dwie równowagi w strategiach czystych, (D, S) oraz (S, D), a także jedną równowagę w strategiach mieszanych (każdy z prawd. 0,1 wybiera Dare).\n","\n","Główna różnica zatem polega na tym czy bierzemy pod uwagę decyzje podjętą przez drugiego gracza, w przypadku strategii dominujących nie bierzemy, a przypadku równowagi Nasha bierzemy."],"metadata":{"id":"Il_9iK_JCx0l"}},{"cell_type":"markdown","source":["# Zadanie: Papier-Nożyce-Kamień"],"metadata":{"id":"WDXJheVZqFS9"}},{"cell_type":"markdown","source":["Dwóch graczy (Gracz A i Gracz B) wielokrotnie rozgrywa Papier-Nożyce-Kamień w środowisku uczenia wieloagentowego. W każdej rundzie wybierają jedną z trzech akcji: Kamień (R), Papier (P) lub Nożyce (S). Zasady przyznawania wypłat (payoff) są standardowe:\n","\n","- Kamień bije Nożyce (+1 dla zwycięzcy, –1 dla przegranego),\n","- Papier bije Kamień (+1, –1),\n","- Nożyce biją Papier (+1, –1),\n","- Remis (ta sama akcja) oznacza 0 dla obu graczy.\n","\n","Zadania:\n","- Określ graczy i ich zbiory akcji.\n","- Zbuduj macierz wypłat dla Gracza A (gracz wierszy) i Gracza B (gracz kolumn) w formie normalnej.\n","- Sprawdź, czy któraś z akcji (R, P lub S) jest strategią dominującą dla któregoś z graczy. Uzasadnij.\n","- Przeanalizuj macierz wypłat w celu znalezienia jakiejkolwiek równowagi Nasha w strategiach czystych (tzn. deterministycznych). Dla każdego możliwego profilu strategii (np. (R, R), (P, S)), sprawdź, czy spełnia warunki równowagi.\n","- Wyjaśnij, na czym polega **zasada obojętności (indifference principle)**.\n","- Równowagą Nasha w strategiach mieszanych (mixed) dla obu graczy jest wektor prawdopodobieństw (1/3, 1/3, 1/3). Uzasadnij, dlaczego tak się dzieje. Zweryfikuj to, obliczając oczekiwane wypłaty (tzw. *utility of joint policy for agent i*). Czy zasada obojętności jest tu spełniona?"],"metadata":{"id":"x9H7ntnUkMNX"}},{"cell_type":"markdown","source":["**Odpowiedź**:\n","\n","**1. Gracze i ich zbiory akcji:**\n","* Gracz A: R, P, S\n","* Gracz B: R, P, S\n","\n","**2. Macierz wypłat dla Gracza A i Gracza B:**\n","\n","\\begin{array}{c|cc} &\n","\\text{Gracz B: R} & \\text{Gracz B: P} & \\text{Gracz B: S} \\\\\n","\\hline\n","\\text{Gracz A: R} & (0, 0) & (-1, +1) & (+1, -1) \\\\\n","\\text{Gracz A: P} & (+1, -1) & (0, 0) & (-1, +1) \\\\\n","\\text{Gracz A: S} & (-1, +1) & (+1, -1) & (0, 0) \\\\\n","\\end{array}\n","\n","**3. Sprawdzenie czy któraś z akcji jest strategią dominującą**\n","\n","* Kamień (R) czasem wygrywa (z Nożycami), czasem przegrywa (z Papierem), czasem remisuje (z Kamieniem).\n","* Papier (P) czasem wygrywa (z Kamieniem), czasem przegrywa (z Nożycami), czasem remisuje (z Papierem).\n","* Nożyce (S) czasem wygrywają (z Papierem), czasem przegrywają (z Kamieniem), czasem remisują (z Nożycami).\n","\n","Żadna akcja nie jest zawsze lepsza lub równa wszystkim innym akcjom dla żadnego z graczy, więc nie ma strategii dominującej ani dla Gracza A, ani dla Gracza B.\n","\n","**4. Analiza macierzy wypłat w celu znalezienia równowagi Nasha**\n","\n","  1. \\((R, R)\\): wypłaty \\((0, 0)\\).\n","   - Jeśli Gracz A jednostronnie zmieni akcję na \\(P\\), to otrzyma \\(+1\\) (zamiast \\(0\\)). Czyli **opłaca się** A zmienić na \\(P\\).\n","   - Podobnie, jeśli Gracz B zmieni akcję na \\(P\\), to B dostanie \\(+1\\).  \n","   **Wniosek**: \\((R, R)\\) nie jest równowagą Nasha.\n","\n","  2. \\((R, P)\\): wypłaty \\((-1, +1)\\).\n","   - Gracz A przegrywa, więc chętnie by zmienił akcję na \\(S\\) (bo \\(S\\) bije \\(P\\)), co dałoby mu \\(+1\\) zamiast \\(-1\\).\n","   - Gracz B, mając \\(P\\), w starciu z \\(R\\) i tak wygrywa \\((+1)\\), więc do tej pory B nie zmienia (z punktu widzenia B jest dobrze).  \n","   **Ale już sam fakt, że A ma zachętę do zmiany, dyskwalifikuje** \\((R,P)\\) jako równowagę Nasha.\n","\n","  3. \\((R, S)\\): wypłaty \\((+1, -1)\\).\n","   - Teraz A wygrywa i raczej nie chce zmienić akcji (dostaje \\(+1\\)).\n","   - Natomiast B, mając \\(S\\), **woli** zmienić na \\(P\\) (bo \\(P\\) bije \\(R\\)), wtedy B miałby \\(+1\\) zamiast \\(-1\\).  \n","   **Zatem** \\((R, S)\\) nie jest równowagą Nasha, ponieważ B ma motywację do zmiany.\n","\n","  4. \\((P, R)\\): wypłaty \\((+1, -1)\\).\n","   - A wygrywa (\\(+1\\)), więc A _nie_ ma motywacji zmieniać.  \n","   - B przegrywa (\\(-1\\)), więc B _woli_ przejść np. na \\(S\\) (bo \\(S\\) bije \\(P\\)), przez co zyska \\(+1\\).  \n","   **Wniosek**: nie jest równowagą Nasha.\n","\n","  5. \\((P, P)\\): wypłaty \\((0, 0)\\).\n","   - Jeśli A przejdzie na \\(S\\), to \\((S,P)\\) daje A \\(+1\\). Zatem A woli zmienić.\n","   - Analogicznie B woli przejść np. na \\(S\\).  \n","   **Wniosek**: nie jest równowagą Nasha.\n","\n","  6. \\((P, S)\\): wypłaty \\((-1, +1)\\).\n","   - A przegrywa, woli więc przejść na \\(R\\) (bo \\(R\\) bije \\(S\\)), by zyskać \\(+1\\).\n","   - B wygrywa, więc nie zmieniałby, ale A ma zachętę do zmiany.  \n","   **Wniosek**: nie jest równowagą Nasha.\n","\n","  7. \\((S, R)\\): wypłaty \\((-1, +1)\\).\n","   - A przegrywa, wolałby przejść na \\(P\\) (bo \\(P\\) bije \\(R\\)).\n","   - B wygrywa, więc jest zadowolony, ale A ma bodziec do zmiany.  \n","   **Wniosek**: nie jest równowagą Nasha.\n","\n","  8. \\((S, P)\\): wypłaty \\((+1, -1)\\).\n","   - A wygrywa, więc sam A nie ma motywacji zmieniać.\n","   - B przegrywa, więc B wolałby przejść na \\(R\\) (bo \\(R\\) bije \\(S\\)).  \n","   **Wniosek**: nie jest równowagą Nasha.\n","\n","  9. \\((S, S)\\): wypłaty \\((0, 0)\\).\n","   - A może przejść na \\(R\\), by uzyskać \\(+1\\).\n","   - B może zrobić to samo.  \n","   **Wniosek**: nie jest równowagą Nasha.\n","\n","Podsumowując, w ramach możliwych profili nie istnieje równowaga Nasha w tej grze.\n","\n","**5. Zasada obojętności**\n","\n","Zasada obojętności mówi, że w równowadze mieszanej każda akcja, która otrzymuje dodatnie prawdopodobieństwo musi dawać taką samą wartość oczekiwaną z punktu widzenia gracza. W grze Papier–Nożyce–Kamień gracz jest „obojętny” wobec wyboru – każda z akcji przynosi tę samą oczekiwaną wartość, ponieważ każda może przynieść wygraną, remis lub przegraną z równym prawdopodobieństwem, jeśli przeciwnik również losuje wszystkie trzy akcje z równymi szansami.\n","\n","**6. Równowaga Nasha w strategiach mieszanych**\n","\n","**6.1. Wyznaczenie miksu \\((1/3,\\;1/3,\\;1/3)\\)**\n","\n","W grze Papier–Nożyce–Kamień jedyna równowaga Nasha w strategiach mieszanych to granie każdej akcji z prawdopodobieństwem 1/3. - Gdyby któryś z graczy grał częściej dowolną wygraną strategię, gracz drugi powinien częściej grać tą, która z tą wybraną wygrywa, co powoduje, że przestaje być to równowagą Nasha.\n","\n","6.2. Obliczenie oczekiwanych wypłat (weryfikacja zasady obojętności)\n","\n","Załóżmy, że Gracz B gra strategią mieszaną taką, że P(R) = P(P) = P(S) = 1/3\n","\n","Oczekiwane wypłaty w zależności od strategii gracza A:\n","1. Gracz A wybiera R: 1/3 * 1 + 1/3 * 0 + 1/3 * -1 = 1/3 + 0 - 1/3 = 0\n","2. Gracz A wybiera P: 1/3 * 1 + 1/3 * 0 + 1/3 * -1 = 1/3 + 0 - 1/3 = 0\n","3. Gracz A wybiera S: 1/3 * 1 + 1/3 * 0 + 1/3 * -1 = 1/3 + 0 - 1/3 = 0\n","\n","Każda z trzech akcji A daje przy miksie B (1/3, 1/3, 1/3) tę samą oczekiwaną wypłatę 0. Gracz A jest więc w pełni obojętny między R, P, S, co dokładnie odpowiada zasadzie obojętności – nie może poprawić wyniku jednostronną zmianą wagi między akcjami.\n","\n","Symetrycznie, jeśli Gracz A stosuje (1/3, 1/3, 1/3), to i dla Gracza B oczekiwana wypłata ze wszystkich trzech możliwych akcji wynosi \\(0\\). W efekcie nikt nie ma motywacji do zmiany swojej strategii, jeśli przeciwnik używa równomiernej mieszanki.\n","\n","**Wniosek**: Profil (1/3, 1/3, 1/3) dla Gracza A i (1/3, 1/3, 1/3) dla Gracza B jest równowagą Nasha w strategiach mieszanych.  \n","\n","Dodatkowo, zasada obojętności mówi, że skoro wszystkie trzy akcje dają w tej równowadze taką samą (zerową) oczekiwaną wypłatę, to każdy z graczy jest „obojętny”, jaką akcję dokładnie wybiera – ważne jest jedynie to, by *przeciwnik* nie przesunął się w kierunku jednej z akcji za bardzo.\n"],"metadata":{"id":"FxayYauYw_dj"}}]}