{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/nsight-systems-2023.2.3_2023.2.3.1001-1_amd64.deb\n",
        "!apt update\n",
        "!apt install ./nsight-systems-2023.2.3_2023.2.3.1001-1_amd64.deb\n",
        "!apt --fix-broken install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6QelIrE_VL2",
        "outputId": "25ee4f55-1b95-4a9c-d009-7690445452d4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-21 16:07:00--  https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/nsight-systems-2023.2.3_2023.2.3.1001-1_amd64.deb\n",
            "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 152.199.20.126\n",
            "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|152.199.20.126|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 317705436 (303M) [application/x-deb]\n",
            "Saving to: ‘nsight-systems-2023.2.3_2023.2.3.1001-1_amd64.deb’\n",
            "\n",
            "nsight-systems-2023 100%[===================>] 302.99M   207MB/s    in 1.5s    \n",
            "\n",
            "2023-10-21 16:07:01 (207 MB/s) - ‘nsight-systems-2023.2.3_2023.2.3.1001-1_amd64.deb’ saved [317705436/317705436]\n",
            "\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:2 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:8 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [555 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [1,305 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1,330 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,009 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,131 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,274 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,398 kB]\n",
            "Fetched 8,344 kB in 2s (3,372 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "19 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'nsight-systems-2023.2.3' instead of './nsight-systems-2023.2.3_2023.2.3.1001-1_amd64.deb'\n",
            "The following additional packages will be installed:\n",
            "  libtinfo5 libxcb-icccm4 libxcb-image0 libxcb-keysyms1 libxcb-render-util0 libxcb-util1\n",
            "  libxcb-xinerama0 libxcb-xinput0 libxcb-xkb1 libxkbcommon-x11-0 libxtst6\n",
            "The following NEW packages will be installed:\n",
            "  libtinfo5 libxcb-icccm4 libxcb-image0 libxcb-keysyms1 libxcb-render-util0 libxcb-util1\n",
            "  libxcb-xinerama0 libxcb-xinput0 libxcb-xkb1 libxkbcommon-x11-0 libxtst6 nsight-systems-2023.2.3\n",
            "0 upgraded, 12 newly installed, 0 to remove and 19 not upgraded.\n",
            "Need to get 318 MB of archives.\n",
            "After this operation, 1,269 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libtinfo5 amd64 6.3-2ubuntu0.1 [100 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xinerama0 amd64 1.14-3ubuntu3 [5,414 B]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xinput0 amd64 1.14-3ubuntu3 [34.3 kB]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nsight-systems-2023.2.3 2023.2.3.1001-32894139v0 [318 MB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xkb1 amd64 1.14-3ubuntu3 [32.8 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbcommon-x11-0 amd64 1.4.0-1 [14.4 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-icccm4 amd64 0.4.1-1.1build2 [11.5 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-util1 amd64 0.4.0-1build2 [11.4 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-image0 amd64 0.4.0-2 [11.5 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-keysyms1 amd64 0.4.0-1build3 [8,746 B]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-render-util0 amd64 0.3.9-1build3 [10.3 kB]\n",
            "Fetched 318 MB in 13s (25.1 MB/s)\n",
            "Selecting previously unselected package libtinfo5:amd64.\n",
            "(Reading database ... 120874 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libtinfo5_6.3-2ubuntu0.1_amd64.deb ...\n",
            "Unpacking libtinfo5:amd64 (6.3-2ubuntu0.1) ...\n",
            "Selecting previously unselected package libxcb-xinerama0:amd64.\n",
            "Preparing to unpack .../01-libxcb-xinerama0_1.14-3ubuntu3_amd64.deb ...\n",
            "Unpacking libxcb-xinerama0:amd64 (1.14-3ubuntu3) ...\n",
            "Selecting previously unselected package libxcb-xinput0:amd64.\n",
            "Preparing to unpack .../02-libxcb-xinput0_1.14-3ubuntu3_amd64.deb ...\n",
            "Unpacking libxcb-xinput0:amd64 (1.14-3ubuntu3) ...\n",
            "Selecting previously unselected package libxcb-xkb1:amd64.\n",
            "Preparing to unpack .../03-libxcb-xkb1_1.14-3ubuntu3_amd64.deb ...\n",
            "Unpacking libxcb-xkb1:amd64 (1.14-3ubuntu3) ...\n",
            "Selecting previously unselected package libxkbcommon-x11-0:amd64.\n",
            "Preparing to unpack .../04-libxkbcommon-x11-0_1.4.0-1_amd64.deb ...\n",
            "Unpacking libxkbcommon-x11-0:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "Preparing to unpack .../05-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package libxcb-icccm4:amd64.\n",
            "Preparing to unpack .../06-libxcb-icccm4_0.4.1-1.1build2_amd64.deb ...\n",
            "Unpacking libxcb-icccm4:amd64 (0.4.1-1.1build2) ...\n",
            "Selecting previously unselected package libxcb-util1:amd64.\n",
            "Preparing to unpack .../07-libxcb-util1_0.4.0-1build2_amd64.deb ...\n",
            "Unpacking libxcb-util1:amd64 (0.4.0-1build2) ...\n",
            "Selecting previously unselected package libxcb-image0:amd64.\n",
            "Preparing to unpack .../08-libxcb-image0_0.4.0-2_amd64.deb ...\n",
            "Unpacking libxcb-image0:amd64 (0.4.0-2) ...\n",
            "Selecting previously unselected package libxcb-keysyms1:amd64.\n",
            "Preparing to unpack .../09-libxcb-keysyms1_0.4.0-1build3_amd64.deb ...\n",
            "Unpacking libxcb-keysyms1:amd64 (0.4.0-1build3) ...\n",
            "Selecting previously unselected package libxcb-render-util0:amd64.\n",
            "Preparing to unpack .../10-libxcb-render-util0_0.3.9-1build3_amd64.deb ...\n",
            "Unpacking libxcb-render-util0:amd64 (0.3.9-1build3) ...\n",
            "Selecting previously unselected package nsight-systems-2023.2.3.\n",
            "Preparing to unpack .../11-nsight-systems-2023.2.3_2023.2.3.1001-32894139v0_amd64.deb ...\n",
            "Unpacking nsight-systems-2023.2.3 (2023.2.3.1001-32894139v0) ...\n",
            "Setting up libxcb-xinput0:amd64 (1.14-3ubuntu3) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up libxcb-keysyms1:amd64 (0.4.0-1build3) ...\n",
            "Setting up libxcb-render-util0:amd64 (0.3.9-1build3) ...\n",
            "Setting up libxcb-icccm4:amd64 (0.4.1-1.1build2) ...\n",
            "Setting up libxcb-util1:amd64 (0.4.0-1build2) ...\n",
            "Setting up libxcb-xkb1:amd64 (1.14-3ubuntu3) ...\n",
            "Setting up libxcb-image0:amd64 (0.4.0-2) ...\n",
            "Setting up libxcb-xinerama0:amd64 (1.14-3ubuntu3) ...\n",
            "Setting up libxkbcommon-x11-0:amd64 (1.4.0-1) ...\n",
            "Setting up libtinfo5:amd64 (6.3-2ubuntu0.1) ...\n",
            "Setting up nsight-systems-2023.2.3 (2023.2.3.1001-32894139v0) ...\n",
            "update-alternatives: using /opt/nvidia/nsight-systems/2023.2.3/target-linux-x64/nsys to provide /usr/local/bin/nsys (nsys) in auto mode\n",
            "update-alternatives: using /opt/nvidia/nsight-systems/2023.2.3/host-linux-x64/nsys-ui to provide /usr/local/bin/nsys-ui (nsys-ui) in auto mode\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "0 upgraded, 0 newly installed, 0 to remove and 20 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehZy6Zhc_QU-"
      },
      "source": [
        "<h1><div align=\"center\">Zarządzanie pamięcią przyspieszonych aplikacji z CUDA C/C++ Unified Memory</div></h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbIwLHk8_QVB"
      },
      "source": [
        "W [*CUDA Best Practices Guide*](http://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#memory-optimizations), przedstawiony jest cykl projektowy zwany **APOD**: **A**ssess, **P**arallelize, **O**ptimize, **D**eploy (Ocena, Paralelizacja, Optymalizacja, Deploy) z którym warto się zapoznać. Krótko mówiąc, APOD zaleca iteracyjny proces projektowania, w którym programiści mogą stopniowo ulepszać swoje aplikacje. Nabierając doświadczenia, można stosować bardziej zaawansowane techniki optymalizacji.\n",
        "\n",
        "Na tych zajęciach przedstawione zostanie narzędzie wierszaq poleceń Nsight Systems **nsys** do pomiaru jakości i wydajności aplikacji, a także identyfikowania możliwości dalszej optymalizacji. Pozwoli to na stopniowe stosowanie ulepszeń na podstawie poznanych technik. Wiele technik będzie dotyczyło **CUDA Unified Memory**. Zrozumienie zarządzania tą pamięcią jest podstawową umiejętnością programistów CUDA i stanowi początek dla wielu bardziej zaawansowanych technik zarządzania pamięcią."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uprpy4Xe_QVB"
      },
      "source": [
        "---\n",
        "## Wymagania\n",
        "\n",
        "Aby sprawnie zrealizować dzisiejsze zadanie, powinniście już umieć:\n",
        "- Pisać, kompilować i uruchamiać programy w języku C/C++, które zarówno wywołują funkcje na CPU oraz **uruchamiają kernele** na GPU.\n",
        "- Kontrolować równoległą **hierarchię wątków** wykorzystując **konfigurację wykonania**.\n",
        "- Przerabiać pętle, aby iteracje wykonywały się równolegle.\n",
        "- Alokować i zwalniać pamięć dostepną zarówno dla procesorów jak i kart graficznych."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9uIn3Qd_QVB"
      },
      "source": [
        "---\n",
        "## Cele\n",
        "\n",
        "Po dzisiejszych zajęciach powinniście być w stanie:\n",
        "\n",
        "- Wykorzystywać Nsight Systems do profilowania wydajności przyspieszonych aplikacji.\n",
        "- Lepiej zrozumieć **streaming multiprocessors**, aby optymalizować konfiguracje wykonawcze.\n",
        "- Zruzumieć zachowanie **unified memory** w odniesieniu do różnego rodzaju błędów i migracji danych.\n",
        "- Wykorzystywać **asynchronous memory prefetching** do zmniejszania liczby błędów i problemów z migracją danych.\n",
        "- Stosować cykl projektowy APOD do przyspieszania i wdrażania przyspieszonych aplikacji."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27H_GiD6_QVC"
      },
      "source": [
        "---\n",
        "## Optymalizacje z wykorzystaniem programu NVIDIA Command Line Profiler\n",
        "\n",
        "Jednym ze sposobów na upewnienie się, że próby optymalizacji kodu są skuteczne jest profilowanie aplikacji pod kątem informacji o ich wydajności. `nsys` to narzędzie wiersza poleceń Nsight Systems. Jest dostarczany wraz z innymi narzędziami CUDA i umożliwia właśnie profilowanie przyspieszonych aplikacji.\n",
        "\n",
        "`nsys` jest łatwy w uzyciu. Jego najbardziej podstawowym zastosowaniem jest po prostu przekazanie mu ścieżki do pliku wykonywalnego, skompilowanego z użyciem `nvcc`. `nsys` wykona kod aplikacji, a następnie wydrukuje podsumowanie jego działania wykorzystujące GPU, wywołania API CUDA, a także informacje na temat **unified memory**.\n",
        "\n",
        "Podczas przyspieszania aplikacji czy też optymalizacji istniejących już rozwiązań należy stosować różne techniki. Przede wszystkim należy profilować aplikacje po dokonaniu zmian i odnotowywać ich wpływ na wydajność. Na podstawowym etapie należy dość często dokonywać profilowania, aby zapoznać się z narzędziami oraz nauczyć się, w jaki sposób określone zmiany w kodzie CUDA wpływają na jego rzeczywistą wydajność. Jeśli dokonamy wielu zmian, a nastepnie profilowania, ciężko będzie dojść do tego co miało większy wpływ na przyspieszenie aplikacji."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0i0EEQl_QVC"
      },
      "source": [
        "### Ćwiczenie: Profilowanie aplikacji za pomocą nsys\n",
        "01-vector-add.cu jest podstawową wersją wykorzystującą GPU w celu przyspieszenia programu dodającego wektory. Pierwsza komórka wykonania kodu skompiluje (i uruchomi) program dodawania wektorów. Druga komórka wykonania kodu będzie profilować plik wykonywalny, który właśnie został skompilowany, przy użyciu `nsys profile`.\n",
        "\n",
        "`nsys profile` wygeneruje plik raportu `qdrep`, który można użyć na różne sposoby. Używamy tutaj flagi `--stats=true`, aby wskazać, że chcemy wyświetlić podsumowanie statystyk takie jak:\n",
        "\n",
        "- Szczegóły konfiguracji\n",
        "- Szczegóły generowania plików\n",
        "- **Statystyki API CUDA**\n",
        "- **Statystyki kerneli CUDA**\n",
        "- **Statystyki operacji pamięci CUDA (czas i rozmiar)**\n",
        "- Statystyki interfejsu API środowiska wykonawczego systemu operacyjnego"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIY0WnIb_QVC"
      },
      "source": [
        "Po profilowaniu aplikacji odpowiedz na następujące pytania, korzystając z informacji wyświetlanych w sekcji `CUDA Kernel Statistics` wyniku profilowania:\n",
        "\n",
        "- Jak nazywał się jedyny kernel CUDA wywoływany w tej aplikacji?\n",
        "- Ile razy się uruchomił?\n",
        "- Jak długo trwało jego uruchomienie? Należy zapisać gdzieś ten czas, aby śledzić wpływ dokonywanych później optymalizacji na jego przyspieszenie."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjkFT8F8_QVD",
        "outputId": "55e47ca6-678a-49f9-e77a-5a79c4b1e4f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success! All values calculated correctly.\n"
          ]
        }
      ],
      "source": [
        "!nvcc -o single-thread-vector-add 01-vector-add.cu -run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoUX0GwX_QVD",
        "outputId": "acc3431f-9a1a-4816-b19a-6fa9d7ab6a84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success! All values calculated correctly.\n",
            "Generating '/tmp/nsys-report-7ef3.qdstrm'\n",
            "[1/8] [========================100%] report1.nsys-rep\n",
            "[2/8] [========================100%] report1.sqlite\n",
            "[3/8] Executing 'nvtx_sum' stats report\n",
            "SKIPPED: /content/report1.sqlite does not contain NV Tools Extension (NVTX) data.\n",
            "[4/8] Executing 'osrt_sum' stats report\n",
            "\n",
            " Time (%)  Total Time (ns)  Num Calls    Avg (ns)      Med (ns)    Min (ns)   Max (ns)    StdDev (ns)        Name     \n",
            " --------  ---------------  ---------  ------------  ------------  --------  -----------  ------------  --------------\n",
            "     98.1    4,714,571,831        246  19,164,926.1  10,078,069.5     5,316  103,206,338  27,469,776.0  poll          \n",
            "      1.2       58,263,697        531     109,724.5      13,657.0       367   18,306,522     882,019.1  ioctl         \n",
            "      0.6       27,143,918         24   1,130,996.6       6,360.0       838   10,255,830   3,049,287.0  mmap          \n",
            "      0.0        1,365,856         31      44,059.9       6,893.0     5,281      891,598     158,025.7  mmap64        \n",
            "      0.0          961,825          6     160,304.2      57,433.0    28,736      709,129     269,446.0  sem_timedwait \n",
            "      0.0          446,549         49       9,113.2       8,450.0     2,459       22,368       3,234.3  open64        \n",
            "      0.0          185,639         39       4,760.0       3,270.0     1,743       25,134       4,121.1  fopen         \n",
            "      0.0          110,377          2      55,188.5      55,188.5    46,543       63,834      12,226.6  pthread_create\n",
            "      0.0          110,285         11      10,025.9       6,501.0     1,309       24,258       8,690.1  write         \n",
            "      0.0           49,777         32       1,555.5       1,418.5       934        4,645         740.9  fclose        \n",
            "      0.0           46,818          5       9,363.6       8,438.0     3,248       19,898       6,309.4  open          \n",
            "      0.0           44,314         11       4,028.5       3,835.0     2,030        9,276       1,993.7  munmap        \n",
            "      0.0           44,019          5       8,803.8       1,846.0        73       22,888      11,152.3  fread         \n",
            "      0.0           36,114         57         633.6         508.0       189        5,268         658.7  fcntl         \n",
            "      0.0           34,689         17       2,040.5          45.0        44       33,852       8,197.6  fgets         \n",
            "      0.0           28,234          2      14,117.0      14,117.0    10,310       17,924       5,383.9  socket        \n",
            "      0.0           20,543         14       1,467.4       1,144.0       331        3,379         960.2  read          \n",
            "      0.0           11,762          1      11,762.0      11,762.0    11,762       11,762           0.0  connect       \n",
            "      0.0            6,842          1       6,842.0       6,842.0     6,842        6,842           0.0  pipe2         \n",
            "      0.0            3,101          8         387.6         403.5       256          508          81.4  dup           \n",
            "      0.0            1,788          1       1,788.0       1,788.0     1,788        1,788           0.0  bind          \n",
            "      0.0              952          1         952.0         952.0       952          952           0.0  listen        \n",
            "\n",
            "[5/8] Executing 'cuda_api_sum' stats report\n",
            "\n",
            " Time (%)  Total Time (ns)  Num Calls     Avg (ns)         Med (ns)        Min (ns)       Max (ns)     StdDev (ns)            Name         \n",
            " --------  ---------------  ---------  ---------------  ---------------  -------------  -------------  ------------  ----------------------\n",
            "     93.7    1,977,161,369          1  1,977,161,369.0  1,977,161,369.0  1,977,161,369  1,977,161,369           0.0  cudaDeviceSynchronize \n",
            "      5.0      106,169,365          3     35,389,788.3         67,004.0         32,167    106,070,194  61,211,029.3  cudaMallocManaged     \n",
            "      1.3       27,243,146          3      9,081,048.7      8,631,000.0      8,294,330     10,317,816   1,084,219.4  cudaFree              \n",
            "      0.0           53,201          1         53,201.0         53,201.0         53,201         53,201           0.0  cudaLaunchKernel      \n",
            "      0.0            1,925          1          1,925.0          1,925.0          1,925          1,925           0.0  cuModuleGetLoadingMode\n",
            "\n",
            "[6/8] Executing 'cuda_gpu_kern_sum' stats report\n",
            "\n",
            " Time (%)  Total Time (ns)  Instances     Avg (ns)         Med (ns)        Min (ns)       Max (ns)     StdDev (ns)                       Name                     \n",
            " --------  ---------------  ---------  ---------------  ---------------  -------------  -------------  -----------  ----------------------------------------------\n",
            "    100.0    1,977,149,338          1  1,977,149,338.0  1,977,149,338.0  1,977,149,338  1,977,149,338          0.0  addVectorsInto(float *, float *, float *, int)\n",
            "\n",
            "[7/8] Executing 'cuda_gpu_mem_time_sum' stats report\n",
            "\n",
            " Time (%)  Total Time (ns)  Count  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)              Operation            \n",
            " --------  ---------------  -----  --------  --------  --------  --------  -----------  ---------------------------------\n",
            "     77.5       38,855,583  2,304  16,864.4   7,183.5     2,335   102,814     24,788.4  [CUDA Unified Memory memcpy HtoD]\n",
            "     22.5       11,263,354    768  14,665.8   6,031.5     1,471    81,598     22,909.8  [CUDA Unified Memory memcpy DtoH]\n",
            "\n",
            "[8/8] Executing 'cuda_gpu_mem_size_sum' stats report\n",
            "\n",
            " Total (MB)  Count  Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)              Operation            \n",
            " ----------  -----  --------  --------  --------  --------  -----------  ---------------------------------\n",
            "    402.653  2,304     0.175     0.033     0.004     1.044        0.301  [CUDA Unified Memory memcpy HtoD]\n",
            "    134.218    768     0.175     0.033     0.004     1.044        0.301  [CUDA Unified Memory memcpy DtoH]\n",
            "\n",
            "Generated:\n",
            "    /content/report1.nsys-rep\n",
            "    /content/report1.sqlite\n"
          ]
        }
      ],
      "source": [
        "!nsys profile --stats=true ./single-thread-vector-add"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EYYQMrG_QVD"
      },
      "source": [
        "Warto wspomnieć, że domyślnie `nsys profile` nie nadpisuje istniejącego pliku raportu. Ma to na celu zapobieganie przypadkowej utracie pracy podczas profilowania. Jeśli z jakiegokolwiek powodu wolisz nadpisać istniejący plik raportu, na przykład podczas szybkich zmian, możesz podać flagę `-f` do `profilu nsys`, aby umożliwić nadpisanie istniejącego pliku raportu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAH3Ct90_QVE"
      },
      "source": [
        "### Ćwiczenie: Optimize and Profile\n",
        "\n",
        "Na początek należy zmienić konfigurację wykonania 01-vector-add.cu, aby wykorzystywała więcej bloków i wątków. Nastepnie zrekompilować i zprofilować zmiany z wykorzystaniem `nsys profile --stats=true`. Należy zwrócić uwagę czy tak podstawowa zmiana miała wpływ na czas wykonywania."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1qZKuzf_QVE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93bb1d95-468d-4402-9afb-4c9b45cd9b93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success! All values calculated correctly.\n"
          ]
        }
      ],
      "source": [
        "!nvcc -o multi-thread-vector-add 01-vector-add.cu -run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKBq3afm_QVE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58c653fb-25c7-4418-d2f4-373b8ec38972"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: LBR backtrace method is not supported on this platform. DWARF backtrace method will be used.\n",
            "Collecting data...\n",
            "Success! All values calculated correctly.\n",
            "\n",
            "The target application terminated with signal 11 (SIGSEGV)\n",
            "Processing events...\n",
            "Capturing symbol files...\n",
            "Saving temporary \"/tmp/nsys-report-043f-17fc-feb1-4bd9.qdstrm\" file to disk...\n",
            "Creating final output files...\n",
            "\n",
            "Processing [==============================================================100%]\n",
            "Saved report file to \"/tmp/nsys-report-043f-17fc-feb1-4bd9.qdrep\"\n",
            "Exporting 18508 events: [=================================================100%]\n",
            "\n",
            "Exported successfully to\n",
            "/tmp/nsys-report-043f-17fc-feb1-4bd9.sqlite\n",
            "\n",
            "\n",
            "CUDA API Statistics:\n",
            "\n",
            " Time(%)  Total Time (ns)  Num Calls     Average       Minimum      Maximum            Name         \n",
            " -------  ---------------  ---------  -------------  -----------  -----------  ---------------------\n",
            "    55.3      255,165,347          3   85,055,115.7       23,926  255,080,661  cudaMallocManaged    \n",
            "    39.6      182,673,357          1  182,673,357.0  182,673,357  182,673,357  cudaDeviceSynchronize\n",
            "     5.1       23,420,324          3    7,806,774.7    7,152,214    9,002,804  cudaFree             \n",
            "     0.0           56,524          1       56,524.0       56,524       56,524  cudaLaunchKernel     \n",
            "\n",
            "\n",
            "\n",
            "CUDA Kernel Statistics:\n",
            "\n",
            " Time(%)  Total Time (ns)  Instances     Average       Minimum      Maximum                       Name                    \n",
            " -------  ---------------  ---------  -------------  -----------  -----------  -------------------------------------------\n",
            "   100.0      182,654,685          1  182,654,685.0  182,654,685  182,654,685  addVectorsInto(float*, float*, float*, int)\n",
            "\n",
            "\n",
            "\n",
            "CUDA Memory Operation Statistics (by time):\n",
            "\n",
            " Time(%)  Total Time (ns)  Operations  Average   Minimum  Maximum              Operation            \n",
            " -------  ---------------  ----------  --------  -------  -------  ---------------------------------\n",
            "    77.4       39,779,165       2,304  17,265.3    2,687  109,213  [CUDA Unified Memory memcpy HtoD]\n",
            "    22.6       11,599,444         768  15,103.4    1,983   81,887  [CUDA Unified Memory memcpy DtoH]\n",
            "\n",
            "\n",
            "\n",
            "CUDA Memory Operation Statistics (by size in KiB):\n",
            "\n",
            "    Total     Operations  Average  Minimum   Maximum               Operation            \n",
            " -----------  ----------  -------  -------  ---------  ---------------------------------\n",
            " 393,216.000       2,304  170.667    4.000  1,020.000  [CUDA Unified Memory memcpy HtoD]\n",
            " 131,072.000         768  170.667    4.000  1,020.000  [CUDA Unified Memory memcpy DtoH]\n",
            "\n",
            "\n",
            "\n",
            "Operating System Runtime API Statistics:\n",
            "\n",
            " Time(%)  Total Time (ns)  Num Calls    Average     Minimum    Maximum         Name     \n",
            " -------  ---------------  ---------  ------------  -------  -----------  --------------\n",
            "    85.5    1,647,827,422         85  19,386,205.0   57,975  100,160,057  poll          \n",
            "     8.7      168,306,564         74   2,274,413.0   34,180   20,746,716  sem_timedwait \n",
            "     5.7      110,293,504        668     165,110.0    1,033   17,853,118  ioctl         \n",
            "     0.1          993,576         82      12,116.8    2,554       27,167  open64        \n",
            "     0.0          188,366          4      47,091.5   42,290       54,986  pthread_create\n",
            "     0.0          150,305         25       6,012.2    2,115       23,495  fopen         \n",
            "     0.0          103,380          3      34,460.0   27,641       38,429  fgets         \n",
            "     0.0           79,038         11       7,185.3    3,967       12,727  write         \n",
            "     0.0           60,917          6      10,152.8    3,572       15,261  open          \n",
            "     0.0           46,084          6       7,680.7    1,029       13,638  fgetc         \n",
            "     0.0           44,964         17       2,644.9    1,037       16,572  fclose        \n",
            "     0.0           28,127          1      28,127.0   28,127       28,127  sem_wait      \n",
            "     0.0           21,487          2      10,743.5    6,708       14,779  socket        \n",
            "     0.0           18,516         12       1,543.0    1,033        2,252  read          \n",
            "     0.0           12,417          3       4,139.0    1,703        6,097  fcntl         \n",
            "     0.0           12,272          1      12,272.0   12,272       12,272  connect       \n",
            "     0.0           10,361          3       3,453.7    1,947        4,627  fread         \n",
            "     0.0            9,383          3       3,127.7    1,429        6,492  msync         \n",
            "     0.0            8,382          1       8,382.0    8,382        8,382  pipe2         \n",
            "     0.0            1,612          1       1,612.0    1,612        1,612  bind          \n",
            "     0.0            1,085          1       1,085.0    1,085        1,085  listen        \n",
            "\n",
            "Report file moved to \"/content/report2.qdrep\"\n",
            "Report file moved to \"/content/report2.sqlite\"\n"
          ]
        }
      ],
      "source": [
        "!nsys profile --stats=true ./multi-thread-vector-add"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3uj-LRM_QVE"
      },
      "source": [
        "### Ćwiczenie: Optimize Iteratively\n",
        "\n",
        "W tym ćwiczeniu należy dokonać kilku edycji konfiguracji wykonawczej 01-vector-add.cu, a następnie profilowania aby zobaczyć ich wpływ na wydajność. Kroki do zrealizowania:\n",
        "\n",
        "- Przemyśl od 3 do 5 różnych sposobów zmiany konfiguracji wykonawczej, pamiętając o różnych kombinacjach rozmiarów bloków i grid.\n",
        "- Dokonaj edycji 01-vector-add.cu na jeden z wybranych sposobów.\n",
        "- Zkompiluj i dokonaj profilowania.\n",
        "- Odnotuj czas wykonywania po zmianach.\n",
        "- Powtórz edycję -> profilowanie -> odnotowanie wyników dla każdego wymyślonego sposobu.\n",
        "\n",
        "Która konfiguracja wykonawcza przyniosła najlepsze efekty?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvpxuFM7_QVE"
      },
      "outputs": [],
      "source": [
        "!nvcc -o iteratively-optimized-vector-add 01-vector-add.cu -run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xd6xPdqD_QVE"
      },
      "outputs": [],
      "source": [
        "!nsys profile --stats=true ./iteratively-optimized-vector-add"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5ZSYF8Q_QVE"
      },
      "source": [
        "---\n",
        "## Streaming Multiprocessors and Querying the Device\n",
        "\n",
        "Dostępny sprzęt GPU ma ogromne znaczenie na możliwości optymalizacji i przyspieszania aplikacji. Ważnymi elementami są **streaming multiprocessors**. Prezentacja `p1.pptx` przedstawia nadchodzący materiał na wysokim poziomie.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RN-Qs5-j_QVE"
      },
      "source": [
        "### Streaming Multiprocessors and Warps\n",
        "\n",
        "Procesory GPU, na których działają aplikacje CUDA mają jednostki przetwarzania zwane **streaming multiprocessors** (SM). Podczas uruchamiania kerneli, bloki wątków są przekazywane do SM w celu wykonania. Jednym z podstawowych sposobów na zwiększenie liczby operacji równoległych, które mają wpływ na wzrost wydajności, jest *dobieranie liczby bloków będących wielokrotnością liczby SM na danym GPU.*\n",
        "\n",
        "Ponadto SM tworzą, zarządzają, planują i wykonują grupy wątków z danego bloku zwane **warps**. **Warps** składają się z 32 wątków. [Jest to temat zaawansowany i warty zapoznania](http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#hardware-implementation). Warto jednak wspomnieć, że wzrost wydajności można też osiągnąć poprzez *ustalanie wielkości bloku tak, aby liczba jego wątków była wielokrotnością 32.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Bkqi26T_QVF"
      },
      "source": [
        "### Wysyłanie zapytań o właściwości urzadzenia GPU\n",
        "\n",
        "Liczba SM różni się na GPU w zależności od danej architektury. W związku z tym nie powinna znajdować się w kodzie jako zmienna statyczna.\n",
        "\n",
        "Ponizszy kod pokazuje, jak w CUDA C/C++ uzyskać strukturę, która zawiera wiele właściwości dotyczących aktualnie aktywnego GPU, w tym liczbę SM:\n",
        "\n",
        "```cpp\n",
        "int deviceId;\n",
        "cudaGetDevice(&deviceId);                  // `deviceId` now points to the id of the currently active GPU.\n",
        "\n",
        "cudaDeviceProp props;\n",
        "cudaGetDeviceProperties(&props, deviceId); // `props` now has many useful properties about\n",
        "                                           // the active GPU device.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDFQby9t_QVF"
      },
      "source": [
        "### Ćwiczenie: Właściwości GPU\n",
        "\n",
        "Obecnie 01-get-device-properties.cu zawiera wiele nieprzypisanych zmiennych i wyświetla nic nieznaczące informacje, które powinny wyświetlać szczegółowe informacje o aktualnie aktywnym GPU.\n",
        "\n",
        "Dokonaj refaktoryzacji, aby 01-get-device-properties.cu wyświetlały szczegółowe informacje na temat wykorzystywanego urządzenia. Więcej na ten temat można znaleźć w [CUDA Runtime Docs](http://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html). Najważniejsze informacje to:\n",
        "- Możliwości obliczeniowe (Compute Capability).\n",
        "- Liczba Streaming Multiprocessors.\n",
        "- Rozmiar Warp (Warp Size)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PM02SDj5foyj",
        "outputId": "feaf13b5-18ac-4fdc-ee80-59ef1a8008b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Nov 16 11:51:50 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fFh_SwI_QVF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac7391ad-38c7-4a4f-951c-971fa9cb42b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device ID: 0\n",
            "Number of SMs: 40\n",
            "Compute Capability Major: 7\n",
            "Compute Capability Minor: 5\n",
            "Warp Size: 32\n"
          ]
        }
      ],
      "source": [
        "!nvcc -o get-device-properties 01-get-device-properties.cu -run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeGz0nCo_QVF"
      },
      "source": [
        "### Ćwiczenie: Optymalizacja 01-vector-add.cu\n",
        "\n",
        "Wykorzystaj zdobytą wiedzę, aby sprawdzić liczbę SM na wykorzystywanym urządzeniu, a następnie dokonaj refaktoryzacji kernela `addVectorsIno`, aby uruchamiał się z grid zawierającym liczbę bloków będącą wielokrotnością liczby SM na urządzeniu.\n",
        "\n",
        "W zależności od wcześniej dokonanych zmian, ta refaktoryzacja powinna znacząco poprawić (ale nie musi) wydajność kernela. Pamiętaj o użyciu `nsys profile` i ocenić zmiany wydajności."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqNObfvv_QVF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1294302b-8f16-43e2-8c45-7100542d40ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success! All values calculated correctly.\n"
          ]
        }
      ],
      "source": [
        "!nvcc -o sm-optimized-vector-add 01-vector-add.cu -run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5ZwVK7g_QVF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0faf2059-245a-4e18-e13e-cd85bf6fadf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: LBR backtrace method is not supported on this platform. DWARF backtrace method will be used.\n",
            "Collecting data...\n",
            "Success! All values calculated correctly.\n",
            "\n",
            "The target application terminated with signal 11 (SIGSEGV)\n",
            "Processing events...\n",
            "Capturing symbol files...\n",
            "Saving temporary \"/tmp/nsys-report-0ae5-3f79-c533-a433.qdstrm\" file to disk...\n",
            "Creating final output files...\n",
            "\n",
            "Processing [==============================================================100%]\n",
            "Saved report file to \"/tmp/nsys-report-0ae5-3f79-c533-a433.qdrep\"\n",
            "Exporting 19786 events: [=================================================100%]\n",
            "\n",
            "Exported successfully to\n",
            "/tmp/nsys-report-0ae5-3f79-c533-a433.sqlite\n",
            "\n",
            "\n",
            "CUDA API Statistics:\n",
            "\n",
            " Time(%)  Total Time (ns)  Num Calls     Average       Minimum      Maximum            Name         \n",
            " -------  ---------------  ---------  -------------  -----------  -----------  ---------------------\n",
            "    65.6      263,292,176          3   87,764,058.7       16,173  263,221,698  cudaMallocManaged    \n",
            "    28.5      114,466,845          1  114,466,845.0  114,466,845  114,466,845  cudaDeviceSynchronize\n",
            "     5.9       23,812,893          3    7,937,631.0    7,203,441    9,159,831  cudaFree             \n",
            "     0.0           54,113          1       54,113.0       54,113       54,113  cudaLaunchKernel     \n",
            "\n",
            "\n",
            "\n",
            "CUDA Kernel Statistics:\n",
            "\n",
            " Time(%)  Total Time (ns)  Instances     Average       Minimum      Maximum                       Name                    \n",
            " -------  ---------------  ---------  -------------  -----------  -----------  -------------------------------------------\n",
            "   100.0      114,456,150          1  114,456,150.0  114,456,150  114,456,150  addVectorsInto(float*, float*, float*, int)\n",
            "\n",
            "\n",
            "\n",
            "CUDA Memory Operation Statistics (by time):\n",
            "\n",
            " Time(%)  Total Time (ns)  Operations  Average   Minimum  Maximum              Operation            \n",
            " -------  ---------------  ----------  --------  -------  -------  ---------------------------------\n",
            "    79.8       45,944,517       4,390  10,465.7    2,686   98,654  [CUDA Unified Memory memcpy HtoD]\n",
            "    20.2       11,611,915         768  15,119.7    1,983   82,078  [CUDA Unified Memory memcpy DtoH]\n",
            "\n",
            "\n",
            "\n",
            "CUDA Memory Operation Statistics (by size in KiB):\n",
            "\n",
            "    Total     Operations  Average  Minimum   Maximum               Operation            \n",
            " -----------  ----------  -------  -------  ---------  ---------------------------------\n",
            " 393,216.000       4,390   89.571    4.000  1,016.000  [CUDA Unified Memory memcpy HtoD]\n",
            " 131,072.000         768  170.667    4.000  1,020.000  [CUDA Unified Memory memcpy DtoH]\n",
            "\n",
            "\n",
            "\n",
            "Operating System Runtime API Statistics:\n",
            "\n",
            " Time(%)  Total Time (ns)  Num Calls    Average     Minimum    Maximum         Name     \n",
            " -------  ---------------  ---------  ------------  -------  -----------  --------------\n",
            "    84.2    1,492,881,064         79  18,897,228.7   54,617  100,152,141  poll          \n",
            "     9.0      159,830,476         69   2,316,383.7   25,403   20,695,741  sem_timedwait \n",
            "     6.5      114,851,082        668     171,932.8    1,084   17,876,220  ioctl         \n",
            "     0.2        2,798,222          8     349,777.8    4,226    2,734,862  fgetc         \n",
            "     0.1          943,828         82      11,510.1    2,575       27,701  open64        \n",
            "     0.0          220,674          4      55,168.5   42,142       72,755  pthread_create\n",
            "     0.0          143,404         25       5,736.2    1,630       21,620  fopen         \n",
            "     0.0           92,761          3      30,920.3   27,740       36,875  fgets         \n",
            "     0.0           74,161         11       6,741.9    4,058        8,431  write         \n",
            "     0.0           54,792          6       9,132.0    3,360       16,287  open          \n",
            "     0.0           42,541         17       2,502.4    1,035       16,889  fclose        \n",
            "     0.0           29,229          1      29,229.0   29,229       29,229  sem_wait      \n",
            "     0.0           25,866          2      12,933.0    7,279       18,587  socket        \n",
            "     0.0           17,694         12       1,474.5    1,058        1,839  read          \n",
            "     0.0           12,760          1      12,760.0   12,760       12,760  connect       \n",
            "     0.0            9,538          1       9,538.0    9,538        9,538  pipe2         \n",
            "     0.0            8,146          3       2,715.3    1,691        3,492  fread         \n",
            "     0.0            5,034          2       2,517.0    1,052        3,982  fcntl         \n",
            "     0.0            2,664          2       1,332.0    1,329        1,335  msync         \n",
            "     0.0            1,807          1       1,807.0    1,807        1,807  bind          \n",
            "     0.0            1,019          1       1,019.0    1,019        1,019  listen        \n",
            "\n",
            "Report file moved to \"/content/report3.qdrep\"\n",
            "Report file moved to \"/content/report3.sqlite\"\n"
          ]
        }
      ],
      "source": [
        "!nsys profile --stats=true ./sm-optimized-vector-add"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q096mQHI_QVF"
      },
      "source": [
        "---\n",
        "## Unified Memory\n",
        "\n",
        "Do tej pory pamięć przeznaczona do użytku przez kod hosta lub urządzenia była przydzielana za pomocą `cudaMallocManaged`, czyli migracja pamięci była automatyczna. Ułatwia to programowanie, ponieważ nie trzeba zagłębiać się w szczegóły jak **Unified Memory** (**UM**) prydziela rzeczywiste zadania `cudaMallocManaged`.\n",
        "\n",
        "`nsys profile` dostarcza szczegółowych informacji na temat zarządzania UM w akcelerowanych aplikacjach, a ich wykorzystanie w połączeniu z bardziej szczegółowym zrozumieniem działania UM zapewnia dodatkowe możliwości optymalizacji aplikacji.\n",
        "\n",
        "Prezentacja `p2.pptx` przedstawia tę ideę na wysokim poziomie."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FybnCG6t_QVF"
      },
      "source": [
        "### Migracja Unified Memory\n",
        "\n",
        "Po przydzieleniu UM, pamięć nie znajduje się jeszcze ani na hoście ani na urządzeniu. Gdy host lub urządzenie spróbuje uzyskać dostęp do pamięci, wystapi błąd zwany [page fault](https://en.wikipedia.org/wiki/Page_fault), a host lub urządzenie będzie przeprowadzało partiami migrację potrzebnych danych. Dzieje się tak za każdym razem, kiedy aplikacja będzie odwoływała się do pamięci GPU lub CPU, ale nie znajduje się ona jeszcze na żądanym urzadzeniu.\n",
        "\n",
        "Możliwość stronicowania błędów (`page fault`) i migracji pamięci na żądanie jest niezwykle pomocna podczas programowania przyspieszonych aplikacji. Ponadto w przypadku kiedy niewiadomo nad którymi danymi trzeba będzie pracować dopóki aplikacja nie zostanie uruchomiona lub aplikacja będzie wykorzystywała wiele urządzeń GPU, migracja pamięci na rządanie jest niezwykle korzystna.\n",
        "\n",
        "Przykładowo, gdy potrzeby w zagresie danych są znane przed uruchomieniem i wymagane są duże, ciągłe bloki pamięci, `page fault` i migracja danych na rządanie wiąże się z konsekwencjami, których lepiej byłoby uniknąć.\n",
        "\n",
        "Dalsza częśc skupia się na zrozumieniu migracji na żądanie i sposobom jej identyfikowania w danych wyjściowych profilera."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCY8Y_YF_QVF"
      },
      "source": [
        "### Ćwiczenie: Migracja UM i Page Faulting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXDhigpr_QVG"
      },
      "source": [
        "`nsys profile` dostarcza informacje na temat zachowania UM dla profilowanej aplikacji. W tym ćwiczeniu należy wprowadzić kilka modyfikacji i użyć `nsys profile` po każdej zmianie, aby zbadać jak zachowuje się migracja danych UM.\n",
        "\n",
        "`01-page-faults.cu` zawiera `hostFunction` i `gpuKernel`, które moga być użyte do inicjalizacji elementów `2<<24` wektora liczbą `1`. Obecnie nie jest używana ani funkcja hosta, ani kernel GPU.\n",
        "\n",
        "Odpowiedz na poniższe pytania, biorąc pod uwagę wiedzę na temat UM. Należy zacząć od postawienia hipotezy jaki rodzaj błędu `page fault` powinien się wydarzyć, a następnie dokonać edycji jednej lub obu z dwóch dostarczonych funkcji w `01-page-faults.cu` aby przetestować tę hipotezę.\n",
        "\n",
        "Aby tego dokonać należy skompilować i sprofilować kod i zapisać wyniki uzyskane z `nsys profile --stats=true`. Należy zwrócić uwagę na:\n",
        "\n",
        "- Czy w danych wyjściowych znajduje się sekcja _CUDA Memory Operation Statistics_?\n",
        "- Jeśli tak, czy wskazuje migracje z hosta na urządzenie (HtoD) lub z urządzenia na host (DtoH)?\n",
        "- W przypadku migracji, co dane wyjściowe mówią o liczbie występujących _Operations_? Jeśli występuje wiele małych operacji migracji, może być to znak że wystepują błędy `page faulting` z małymi migracjami pamięci występującymi za każdym razem, gdy w żądanej lokalizacji występuje błąd stronicowania."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbISnjor_QVG"
      },
      "source": [
        "Pytania na które należy odpowiedzieć (w razie problemów rozwiązania można znaleźć w folderze _Solutions_ dla odpowiednich pytań):\n",
        "\n",
        "- Czy istnieją dowody na migrację pamięci i/lub `page faulting` gdy tylko CPU uzyskuje dostęp do UM?\n",
        "- Czy istnieją dowody na migrację pamięci i/lub `page faulting` gdy tylko GPU uzyskuje dostęp do UM?\n",
        "- Czy istnieją dowody na migrację pamięci i/lub `page faulting`, gdy UM jest najpierw uzyskiwana przez procesor, a następnie przez GPU?\n",
        "- Czy istnieją dowody na migrację pamięci i/lub `page faulting`, gdy UM jest uzyskiwana najpierw przez GPU, a następnie przez CPU?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRBDT2_E_QVG"
      },
      "outputs": [],
      "source": [
        "!nvcc -o page-faults 01-page-faults.cu -run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEu4od73_QVG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69edf425-3d1c-4cef-d915-82f4f2d0e740"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: LBR backtrace method is not supported on this platform. DWARF backtrace method will be used.\n",
            "Collecting data...\n",
            "\n",
            "The target application terminated with signal 11 (SIGSEGV)\n",
            "Processing events...\n",
            "Capturing symbol files...\n",
            "Saving temporary \"/tmp/nsys-report-b99c-e03e-94bb-485c.qdstrm\" file to disk...\n",
            "Creating final output files...\n",
            "\n",
            "Processing [==============================================================100%]\n",
            "Saved report file to \"/tmp/nsys-report-b99c-e03e-94bb-485c.qdrep\"\n",
            "Exporting 12152 events: [=================================================100%]\n",
            "\n",
            "Exported successfully to\n",
            "/tmp/nsys-report-b99c-e03e-94bb-485c.sqlite\n",
            "\n",
            "\n",
            "CUDA API Statistics:\n",
            "\n",
            " Time(%)  Total Time (ns)  Num Calls     Average       Minimum      Maximum            Name         \n",
            " -------  ---------------  ---------  -------------  -----------  -----------  ---------------------\n",
            "    79.3      245,410,749          1  245,410,749.0  245,410,749  245,410,749  cudaMallocManaged    \n",
            "    18.4       56,973,233          1   56,973,233.0   56,973,233   56,973,233  cudaDeviceSynchronize\n",
            "     2.3        7,204,996          1    7,204,996.0    7,204,996    7,204,996  cudaFree             \n",
            "     0.0           75,195          1       75,195.0       75,195       75,195  cudaLaunchKernel     \n",
            "\n",
            "\n",
            "\n",
            "CUDA Kernel Statistics:\n",
            "\n",
            " Time(%)  Total Time (ns)  Instances    Average      Minimum     Maximum             Name          \n",
            " -------  ---------------  ---------  ------------  ----------  ----------  -----------------------\n",
            "   100.0       56,958,129          1  56,958,129.0  56,958,129  56,958,129  deviceKernel(int*, int)\n",
            "\n",
            "\n",
            "\n",
            "CUDA Memory Operation Statistics (by time):\n",
            "\n",
            " Time(%)  Total Time (ns)  Operations  Average  Minimum  Maximum              Operation            \n",
            " -------  ---------------  ----------  -------  -------  -------  ---------------------------------\n",
            "   100.0       24,915,828       5,168  4,821.2    2,655   32,031  [CUDA Unified Memory memcpy HtoD]\n",
            "\n",
            "\n",
            "\n",
            "CUDA Memory Operation Statistics (by size in KiB):\n",
            "\n",
            "    Total     Operations  Average  Minimum  Maximum              Operation            \n",
            " -----------  ----------  -------  -------  -------  ---------------------------------\n",
            " 131,072.000       5,168   25.362    4.000  192.000  [CUDA Unified Memory memcpy HtoD]\n",
            "\n",
            "\n",
            "\n",
            "Operating System Runtime API Statistics:\n",
            "\n",
            " Time(%)  Total Time (ns)  Num Calls    Average     Minimum    Maximum         Name     \n",
            " -------  ---------------  ---------  ------------  -------  -----------  --------------\n",
            "    79.1      733,358,749         39  18,804,070.5   45,993  100,139,722  poll          \n",
            "    11.3      104,377,362        659     158,387.5    1,262   17,745,112  ioctl         \n",
            "     9.5       88,177,298         32   2,755,540.6   28,228   20,578,690  sem_timedwait \n",
            "     0.1          901,293         82      10,991.4    3,011       24,525  open64        \n",
            "     0.0          185,560          4      46,390.0   40,847       56,751  pthread_create\n",
            "     0.0          145,931         11      13,266.5    4,222       57,743  write         \n",
            "     0.0          145,764         25       5,830.6    1,373       17,828  fopen         \n",
            "     0.0          110,985          3      36,995.0   29,679       46,864  fgets         \n",
            "     0.0           54,049         18       3,002.7    1,086       15,390  fclose        \n",
            "     0.0           53,565          6       8,927.5    3,356       15,148  open          \n",
            "     0.0           43,368          7       6,195.4    1,887        9,394  fgetc         \n",
            "     0.0           30,692          1      30,692.0   30,692       30,692  sem_wait      \n",
            "     0.0           23,118          3       7,706.0    1,768       15,463  fread         \n",
            "     0.0           23,115          2      11,557.5   10,971       12,144  socket        \n",
            "     0.0           15,675         11       1,425.0    1,087        1,837  read          \n",
            "     0.0            9,946          1       9,946.0    9,946        9,946  connect       \n",
            "     0.0            8,249          3       2,749.7    1,055        5,224  fcntl         \n",
            "     0.0            8,127          1       8,127.0    8,127        8,127  pipe2         \n",
            "     0.0            4,698          4       1,174.5    1,048        1,464  msync         \n",
            "     0.0            1,462          1       1,462.0    1,462        1,462  bind          \n",
            "     0.0            1,093          1       1,093.0    1,093        1,093  listen        \n",
            "\n",
            "Report file moved to \"/content/report4.qdrep\"\n",
            "Report file moved to \"/content/report4.sqlite\"\n"
          ]
        }
      ],
      "source": [
        "!nsys profile --stats=true ./page-faults"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOMIQeOd_QVG"
      },
      "source": [
        "### Ćwiczenie: Zachowanie UM w 01-vector-add.cu\n",
        "\n",
        "Analizując kod `01-vector-add.cu` należy zastanowić się jakiego rodzaju migracji pamięci lub błędy stronicowania moga wystąpić. Informacje te można obserwując sekcję _CUDA Memory Operation Statistics_ wyświetloną przez `nsys profile`. Czy można wyjaśnić rodzaje migracji i liczbę ich operacje na podstawie kodu?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBtDUzEG_QVG"
      },
      "outputs": [],
      "source": [
        "!nsys profile --stats=true ./sm-optimized-vector-add"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75HmFfEh_QVG"
      },
      "source": [
        "### Ćwiczenie: Inicjalizacja wektora w kernelu\n",
        "\n",
        "Kiedy `nsys profile` podaje ilość czasu potrzebnego do wykonania kernela, błędy stronicowania między hostem a urządzeniem oraz migracje danych, które występują podczas wykonywania tego kernela są uwzględniane w wyświetlanym czasie wykonania.\n",
        "\n",
        "Mając to na uwadze, zrefaktoryzuj funkcję hosta `initWith` w 01-vector-add.cu tak, aby zamiast tego była kernelem CUDA, inicjując przydzielony wektor równolegle na GPU. Po pomyślnym skompilowaniu i uruchomieniu refaktoryzowanej aplikacji, ale przed jej profilowaniem, rozważ następujące kwestie:\n",
        "\n",
        "- Jak dokonane zmiany mogą wpłynąć na zachowanie migracji UM?\n",
        "- Jak dokonane zmiany mogą wpłynąć na czas wykonywania `addVectorsInto`?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqfXjqrD_QVG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b4d629f-55c3-44cc-b0c5-6d14591d21f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device ID: 0\tNumber of SMs: 40\n",
            "Success! All values calculated correctly.\n"
          ]
        }
      ],
      "source": [
        "!nvcc -o initialize-in-kernel 01-vector-add.cu -run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RU_G4g-_QVG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e4f5050-a6d4-4a93-8114-707fd8a2eed0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: LBR backtrace method is not supported on this platform. DWARF backtrace method will be used.\n",
            "Collecting data...\n",
            "Device ID: 0\tNumber of SMs: 40\n",
            "Success! All values calculated correctly.\n",
            "\n",
            "The target application terminated with signal 11 (SIGSEGV)\n",
            "Processing events...\n",
            "Capturing symbol files...\n",
            "Saving temporary \"/tmp/nsys-report-cd3c-96eb-a5e5-4946.qdstrm\" file to disk...\n",
            "Creating final output files...\n",
            "\n",
            "Processing [==============================================================100%]\n",
            "Saved report file to \"/tmp/nsys-report-cd3c-96eb-a5e5-4946.qdrep\"\n",
            "Exporting 7313 events: [==================================================100%]\n",
            "\n",
            "Exported successfully to\n",
            "/tmp/nsys-report-cd3c-96eb-a5e5-4946.sqlite\n",
            "\n",
            "\n",
            "CUDA API Statistics:\n",
            "\n",
            " Time(%)  Total Time (ns)  Num Calls    Average      Minimum     Maximum            Name         \n",
            " -------  ---------------  ---------  ------------  ---------  -----------  ---------------------\n",
            "    77.7      255,297,074          3  85,099,024.7     22,697  255,210,353  cudaMallocManaged    \n",
            "    15.7       51,770,695          2  25,885,347.5  1,708,237   50,062,458  cudaDeviceSynchronize\n",
            "     6.5       21,521,755          3   7,173,918.3  6,354,093    8,795,486  cudaFree             \n",
            "     0.0          116,354          4      29,088.5      7,651       45,787  cudaLaunchKernel     \n",
            "\n",
            "\n",
            "\n",
            "CUDA Kernel Statistics:\n",
            "\n",
            " Time(%)  Total Time (ns)  Instances    Average      Minimum     Maximum                       Name                   \n",
            " -------  ---------------  ---------  ------------  ----------  ----------  ------------------------------------------\n",
            "    96.7       50,079,801          3  16,693,267.0  14,439,986  20,537,733  initWith(float, float*, int)              \n",
            "     3.3        1,703,673          1   1,703,673.0   1,703,673   1,703,673  addArraysInto(float*, float*, float*, int)\n",
            "\n",
            "\n",
            "\n",
            "CUDA Memory Operation Statistics (by time):\n",
            "\n",
            " Time(%)  Total Time (ns)  Operations  Average   Minimum  Maximum              Operation            \n",
            " -------  ---------------  ----------  --------  -------  -------  ---------------------------------\n",
            "   100.0       11,646,947         768  15,165.3    1,951   91,742  [CUDA Unified Memory memcpy DtoH]\n",
            "\n",
            "\n",
            "\n",
            "CUDA Memory Operation Statistics (by size in KiB):\n",
            "\n",
            "    Total     Operations  Average  Minimum   Maximum               Operation            \n",
            " -----------  ----------  -------  -------  ---------  ---------------------------------\n",
            " 131,072.000         768  170.667    4.000  1,020.000  [CUDA Unified Memory memcpy DtoH]\n",
            "\n",
            "\n",
            "\n",
            "Operating System Runtime API Statistics:\n",
            "\n",
            " Time(%)  Total Time (ns)  Num Calls    Average     Minimum    Maximum         Name     \n",
            " -------  ---------------  ---------  ------------  -------  -----------  --------------\n",
            "    76.5      607,379,772         35  17,353,707.8   39,821  100,132,319  poll          \n",
            "    13.6      107,754,044        668     161,308.4    1,021   18,505,883  ioctl         \n",
            "     9.7       76,951,754         26   2,959,682.8   28,145   20,679,769  sem_timedwait \n",
            "     0.1          875,204         82      10,673.2    2,703       26,847  open64        \n",
            "     0.0          188,759          4      47,189.8   41,855       55,140  pthread_create\n",
            "     0.0          146,919         11      13,356.3    4,431       31,674  write         \n",
            "     0.0          134,115         25       5,364.6    1,321       18,113  fopen         \n",
            "     0.0          105,675          3      35,225.0   30,718       41,157  fgets         \n",
            "     0.0           54,561          6       9,093.5    3,201       14,615  open          \n",
            "     0.0           42,651         16       2,665.7    1,159       16,864  fclose        \n",
            "     0.0           42,526          6       7,087.7    1,033       16,136  fgetc         \n",
            "     0.0           39,095          1      39,095.0   39,095       39,095  sem_wait      \n",
            "     0.0           25,545          4       6,386.3    1,506       10,878  fread         \n",
            "     0.0           20,222          2      10,111.0    6,234       13,988  socket        \n",
            "     0.0           18,251          8       2,281.4    1,138        6,717  read          \n",
            "     0.0           12,119          1      12,119.0   12,119       12,119  connect       \n",
            "     0.0            7,727          1       7,727.0    7,727        7,727  pipe2         \n",
            "     0.0            5,103          2       2,551.5    1,061        4,042  fcntl         \n",
            "     0.0            2,495          2       1,247.5    1,129        1,366  msync         \n",
            "     0.0            1,492          1       1,492.0    1,492        1,492  bind          \n",
            "     0.0            1,087          1       1,087.0    1,087        1,087  listen        \n",
            "\n",
            "Report file moved to \"/content/report5.qdrep\"\n",
            "Report file moved to \"/content/report5.sqlite\"\n"
          ]
        }
      ],
      "source": [
        "!nsys profile --stats=true ./initialize-in-kernel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jl42gBjP_QVG"
      },
      "source": [
        "---\n",
        "## Asynchronous Memory Prefetching\n",
        "\n",
        "Zaawansowana technika zmniejszająca narzut związany z błędami stronicowania i migracjami pamięci na żądanie, zarówno w transferach pamięci między hostami jak i innymi urzadzeniami, nazywana jest **asynchronous memory prefetching** (_asynchroniczne pobieranie z wyprzedzeniem_). Korzystanie z tej techniki umożliwia programistom asynchroniczną migrację UM do dowolnego procesora lub urządzenia GPU w systemie w tle, przed użyciem jej przez kod aplikacji. W ten sposób można zwiększyć wydajność kerneli GPU i funkcji procesora, dzięki ograniczeniu `page faults` i narzutu związanego z migracją danych na żądanie.\n",
        "\n",
        "**Asynchronous memory prefetching** często dokonuje migracji danych w większych porcjach, a zatem z mniejsza ilością migracji niż w przypadku migracji na żadanie. Sprawia to, że doskonale pasuje to, gdy potrzeby w zakresie dostępu do danych są znane przed uruchomieniem.\n",
        "\n",
        "CUDA ułatwią tę technikę w łatwy sposó z wykorzystaniem funkcji `cudaMemPrefetchAsync`. Poniżej znajduje się przykład użycia:\n",
        "\n",
        "```cpp\n",
        "int deviceId;\n",
        "cudaGetDevice(&deviceId);                                         // The ID of the currently active GPU device.\n",
        "\n",
        "cudaMemPrefetchAsync(pointerToSomeUMData, size, deviceId);        // Prefetch to GPU device.\n",
        "cudaMemPrefetchAsync(pointerToSomeUMData, size, cudaCpuDeviceId); // Prefetch to host. `cudaCpuDeviceId` is a\n",
        "                                                                  // built-in CUDA variable.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oms8f6kk_QVG"
      },
      "source": [
        "### Ćwiczenie: Prefetch Memory\n",
        "\n",
        "Aktualnie program `01-vector-add.cu` powinien nie tylko uruchamiać kernel CUDA w celu dodania 2 wektorów do trzeciego, z których wszystkie sa przydzielane za pomocą `cudaMallocManaged`, ale powinien również inicjalizować każdy z 3 wektorów równolegle w kernelu CUDA. Jeśli z jakiegoś powodu aplikacja nie wykonuje powyższych czynności należy zapoznać się z `01-vector-add-init-in- kernel-solution.cu` aby odzwierciedlić jego funkcjonalność we własnym programie.\n",
        "\n",
        "\n",
        "Wykorzystując `cudaMemPrefetchAsync` dokonaj poniższych zmian w `01-vector-add.cu`, aby sprawdzić jaki może mieć wpływ na migrację pamięci i `page faults`:\n",
        "\n",
        "- Co się stanie, gdy pobierzesz z wyprzedzeniem jeden z zainicjowanych wektorów do urządzenia?\n",
        "- Co się stanie, gdy pobierzesz z wyprzedzeniem dwa zainicjowane wektory do urządzenia?\n",
        "- Co się stanie, gdy pobierzesz z wyprzedzeniem wszystkie trzy zainicjowane wektory do urządzenia?\n",
        "\n",
        "Przed kompilacją zastanów się jak zachowa się UM (zwłaszcza page faulting), a także wpływ na czas uruchomienia inicjalizacji kernela."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdhHq7hB_QVH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d02a141d-ca05-4fdc-ee4a-845b4f402f6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success! All values calculated correctly.\n"
          ]
        }
      ],
      "source": [
        "!nvcc -o prefetch-to-gpu 01-vector-add.cu -run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbYhssZ7_QVH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc6ec474-821b-466f-f4d8-b4483d793be2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: LBR backtrace method is not supported on this platform. DWARF backtrace method will be used.\n",
            "Collecting data...\n",
            "Success! All values calculated correctly.\n",
            "\n",
            "The target application terminated with signal 11 (SIGSEGV)\n",
            "Processing events...\n",
            "Capturing symbol files...\n",
            "Saving temporary \"/tmp/nsys-report-24c5-5447-4a22-b068.qdstrm\" file to disk...\n",
            "Creating final output files...\n",
            "\n",
            "Processing [==============================================================100%]\n",
            "Saved report file to \"/tmp/nsys-report-24c5-5447-4a22-b068.qdrep\"\n",
            "Exporting 6827 events: [==================================================100%]\n",
            "\n",
            "Exported successfully to\n",
            "/tmp/nsys-report-24c5-5447-4a22-b068.sqlite\n",
            "\n",
            "\n",
            "CUDA API Statistics:\n",
            "\n",
            " Time(%)  Total Time (ns)  Num Calls    Average      Minimum     Maximum            Name         \n",
            " -------  ---------------  ---------  ------------  ---------  -----------  ---------------------\n",
            "    91.3      260,053,786          3  86,684,595.3     13,812  259,999,540  cudaMallocManaged    \n",
            "     6.4       18,088,459          3   6,029,486.3    834,033   16,326,087  cudaFree             \n",
            "     1.7        4,855,971          1   4,855,971.0  4,855,971    4,855,971  cudaDeviceSynchronize\n",
            "     0.6        1,583,701          3     527,900.3    110,042      759,814  cudaMemPrefetchAsync \n",
            "     0.0          112,133          4      28,033.3      7,645       84,128  cudaLaunchKernel     \n",
            "\n",
            "\n",
            "\n",
            "CUDA Kernel Statistics:\n",
            "\n",
            " Time(%)  Total Time (ns)  Instances    Average     Minimum    Maximum                      Name                    \n",
            " -------  ---------------  ---------  -----------  ---------  ---------  -------------------------------------------\n",
            "    52.3        1,862,678          3    620,892.7    615,858    625,778  initWith(float, float*, int)               \n",
            "    47.7        1,699,545          1  1,699,545.0  1,699,545  1,699,545  addVectorsInto(float*, float*, float*, int)\n",
            "\n",
            "\n",
            "\n",
            "CUDA Memory Operation Statistics (by time):\n",
            "\n",
            " Time(%)  Total Time (ns)  Operations  Average   Minimum  Maximum              Operation            \n",
            " -------  ---------------  ----------  --------  -------  -------  ---------------------------------\n",
            "   100.0       11,659,706         768  15,181.9    1,983   81,822  [CUDA Unified Memory memcpy DtoH]\n",
            "\n",
            "\n",
            "\n",
            "CUDA Memory Operation Statistics (by size in KiB):\n",
            "\n",
            "    Total     Operations  Average  Minimum   Maximum               Operation            \n",
            " -----------  ----------  -------  -------  ---------  ---------------------------------\n",
            " 131,072.000         768  170.667    4.000  1,020.000  [CUDA Unified Memory memcpy DtoH]\n",
            "\n",
            "\n",
            "\n",
            "Operating System Runtime API Statistics:\n",
            "\n",
            " Time(%)  Total Time (ns)  Num Calls    Average     Minimum    Maximum         Name     \n",
            " -------  ---------------  ---------  ------------  -------  -----------  --------------\n",
            "    75.9      562,031,594         32  17,563,487.3   36,565  100,067,752  poll          \n",
            "    15.6      115,481,974        669     172,618.8    1,148   17,813,321  ioctl         \n",
            "     8.3       61,424,796         26   2,362,492.2   26,774   20,492,338  sem_timedwait \n",
            "     0.1          928,611         82      11,324.5    2,752       33,289  open64        \n",
            "     0.0          237,700          5      47,540.0   39,567       66,038  pthread_create\n",
            "     0.0          160,566          3      53,522.0   36,861       76,434  sem_wait      \n",
            "     0.0          128,930         25       5,157.2    1,362       15,338  fopen         \n",
            "     0.0           96,659          3      32,219.7   29,583       36,652  fgets         \n",
            "     0.0           84,950         12       7,079.2    4,356       10,314  write         \n",
            "     0.0           60,707         18       3,372.6    1,066       19,124  fclose        \n",
            "     0.0           58,586          6       9,764.3    3,248       16,859  open          \n",
            "     0.0           28,814          5       5,762.8    1,138       12,867  fgetc         \n",
            "     0.0           21,409          4       5,352.3    2,025       11,464  fread         \n",
            "     0.0           19,062          2       9,531.0    7,865       11,197  socket        \n",
            "     0.0           18,319         12       1,526.6    1,058        2,194  read          \n",
            "     0.0            9,463          1       9,463.0    9,463        9,463  connect       \n",
            "     0.0            8,378          1       8,378.0    8,378        8,378  pipe2         \n",
            "     0.0            6,485          2       3,242.5    1,817        4,668  fcntl         \n",
            "     0.0            5,256          4       1,314.0    1,005        1,769  msync         \n",
            "     0.0            1,501          1       1,501.0    1,501        1,501  bind          \n",
            "     0.0            1,044          1       1,044.0    1,044        1,044  listen        \n",
            "\n",
            "Report file moved to \"/content/report7.qdrep\"\n",
            "Report file moved to \"/content/report7.sqlite\"\n"
          ]
        }
      ],
      "source": [
        "!nsys profile --stats=true ./prefetch-to-gpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vAJUN9r_QVH"
      },
      "source": [
        "### Ćwiczenie: Prefetch Memory spowrotem do CPU\n",
        "\n",
        "Ponownie należy wykorzystać asynchroniczne pobieranie z wyprzedzeniem, tym razem spowrotem do CPU, dla funkcji która sprawdza poprawność kernela `addVectorInto`. Po refaktoryzacji zapoznaj się z wynikiem `nsys`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKi1ombA_QVH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcada1cf-b7d9-4d17-cbfe-29201400436e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success! All values calculated correctly.\n"
          ]
        }
      ],
      "source": [
        "!nvcc -o prefetch-to-cpu 01-vector-add.cu -run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DqFkByT_QVH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9efcf916-5704-4311-ca2b-9740ea156a67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: LBR backtrace method is not supported on this platform. DWARF backtrace method will be used.\n",
            "Collecting data...\n",
            "Success! All values calculated correctly.\n",
            "\n",
            "The target application terminated with signal 11 (SIGSEGV)\n",
            "Processing events...\n",
            "Capturing symbol files...\n",
            "Saving temporary \"/tmp/nsys-report-bc2b-cfad-6b32-ecf0.qdstrm\" file to disk...\n",
            "Creating final output files...\n",
            "\n",
            "Processing [==============================================================100%]\n",
            "Saved report file to \"/tmp/nsys-report-bc2b-cfad-6b32-ecf0.qdrep\"\n",
            "Exporting 4673 events: [==================================================100%]\n",
            "\n",
            "Exported successfully to\n",
            "/tmp/nsys-report-bc2b-cfad-6b32-ecf0.sqlite\n",
            "\n",
            "\n",
            "CUDA API Statistics:\n",
            "\n",
            " Time(%)  Total Time (ns)  Num Calls    Average      Minimum     Maximum            Name         \n",
            " -------  ---------------  ---------  ------------  ---------  -----------  ---------------------\n",
            "    88.8      263,492,743          3  87,830,914.3     15,180  263,430,816  cudaMallocManaged    \n",
            "     5.7       16,856,637          4   4,214,159.3    148,230   15,105,779  cudaMemPrefetchAsync \n",
            "     3.8       11,185,501          3   3,728,500.3    861,484    9,292,132  cudaFree             \n",
            "     1.7        4,944,117          1   4,944,117.0  4,944,117    4,944,117  cudaDeviceSynchronize\n",
            "     0.0          129,400          4      32,350.0      7,636       88,465  cudaLaunchKernel     \n",
            "\n",
            "\n",
            "\n",
            "CUDA Kernel Statistics:\n",
            "\n",
            " Time(%)  Total Time (ns)  Instances    Average     Minimum    Maximum                      Name                    \n",
            " -------  ---------------  ---------  -----------  ---------  ---------  -------------------------------------------\n",
            "    52.2        1,856,546          3    618,848.7    617,089    621,697  initWith(float, float*, int)               \n",
            "    47.8        1,701,058          1  1,701,058.0  1,701,058  1,701,058  addVectorsInto(float*, float*, float*, int)\n",
            "\n",
            "\n",
            "\n",
            "CUDA Memory Operation Statistics (by time):\n",
            "\n",
            " Time(%)  Total Time (ns)  Operations   Average   Minimum  Maximum              Operation            \n",
            " -------  ---------------  ----------  ---------  -------  -------  ---------------------------------\n",
            "   100.0       10,316,937          64  161,202.1  160,832  169,888  [CUDA Unified Memory memcpy DtoH]\n",
            "\n",
            "\n",
            "\n",
            "CUDA Memory Operation Statistics (by size in KiB):\n",
            "\n",
            "    Total     Operations   Average    Minimum    Maximum               Operation            \n",
            " -----------  ----------  ---------  ---------  ---------  ---------------------------------\n",
            " 131,072.000          64  2,048.000  2,048.000  2,048.000  [CUDA Unified Memory memcpy DtoH]\n",
            "\n",
            "\n",
            "\n",
            "Operating System Runtime API Statistics:\n",
            "\n",
            " Time(%)  Total Time (ns)  Num Calls    Average     Minimum   Maximum            Name         \n",
            " -------  ---------------  ---------  ------------  -------  ----------  ---------------------\n",
            "    69.2      421,910,875         27  15,626,328.7   66,932  90,125,399  poll                 \n",
            "    21.4      130,287,829        673     193,592.6    1,121  18,212,215  ioctl                \n",
            "     9.0       54,991,533         23   2,390,936.2   30,473  20,616,254  sem_timedwait        \n",
            "     0.2          998,127         82      12,172.3    2,800      63,048  open64               \n",
            "     0.1          322,035          5      64,407.0   51,390      86,085  pthread_create       \n",
            "     0.0          153,891         25       6,155.6    1,423      25,479  fopen                \n",
            "     0.0          149,109          2      74,554.5   62,446      86,663  sem_wait             \n",
            "     0.0          108,946          3      36,315.3   35,963      36,663  fgets                \n",
            "     0.0           85,925         12       7,160.4    4,408      12,066  write                \n",
            "     0.0           79,531          6      13,255.2    3,585      33,383  open                 \n",
            "     0.0           68,564          7       9,794.9    1,792      25,682  fgetc                \n",
            "     0.0           64,815         18       3,600.8    1,014      29,088  fclose               \n",
            "     0.0           25,791          2      12,895.5    9,192      16,599  socket               \n",
            "     0.0           20,677         13       1,590.5    1,002       2,263  read                 \n",
            "     0.0           19,387          4       4,846.8    1,660       8,256  fread                \n",
            "     0.0           11,553          4       2,888.3    1,096       5,070  fcntl                \n",
            "     0.0            9,131          1       9,131.0    9,131       9,131  connect              \n",
            "     0.0            8,885          1       8,885.0    8,885       8,885  pthread_mutex_trylock\n",
            "     0.0            7,845          1       7,845.0    7,845       7,845  pipe2                \n",
            "     0.0            2,907          2       1,453.5    1,422       1,485  msync                \n",
            "     0.0            1,937          1       1,937.0    1,937       1,937  bind                 \n",
            "     0.0            1,252          1       1,252.0    1,252       1,252  listen               \n",
            "\n",
            "Report file moved to \"/content/report3.qdrep\"\n",
            "Report file moved to \"/content/report3.sqlite\"\n"
          ]
        }
      ],
      "source": [
        "!nsys profile --stats=true ./prefetch-to-cpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osHfdtiV_QVH"
      },
      "source": [
        "Po użyciu _Memory Prefetching_ powinny być zauważalne zmiany, w postaci mniejszej ilości, ale większych transferów pamięci, a czas wykonywania kernela powinien być znacznie skrócony."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rTsDFL3_QVH"
      },
      "source": [
        "---\n",
        "## Podsumowanie\n",
        "\n",
        "Po zajęciach powinniście być w stanie:\n",
        "- Używać narzędzia Nsight Systems (**nsys**) do profilowania aplikacji w celu zwiększania wydajności.\n",
        "- Wykorzystywać wiedze na temat **Streaming Multiprocessors**, aby optymalizować konfiguracje wykonawcze.\n",
        "- Rozumiec zachowanie **Unified Memory** w odniesieniu do migracji danych i `page faults`.\n",
        "- Używać **Memory Prefetching** do zwiększania wydajności.\n",
        "- Stosować iteracyjny proces projektowania, aby szybko przyspieszać i wdrażać aplikacje."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xqpkExQ_QVH"
      },
      "source": [
        "---\n",
        "## Ćwiczenie końcowe: Optymalizacja aplikacji SAXPY\n",
        "\n",
        "W pliku `01-saxpy.cu` znajduje się podstawowa wersja przyspieszonej aplikacji SAXPY. Obecnie zawiera kilka błędów, które należy znaleźć i naprawić, zanim będzie można pomyślnie skompilować, uruchomić, a następnie sprofilować ją za pomoca `nsys profile`.\n",
        "\n",
        "Po naprawie błędów należy skupić się na profilowaniu aplikacji i odnotowywaniu czasu uruchamiania kernela `saxpy` w celu optymalizacji całej aplikacji. W tym celu należy wykorzystać zdobytą wiedzę. Zamiast wyszukiwać w poprzednich rozwiąniach zachęcam do wykorzystania [effortful retrieval](http://sites.gsu.edu/scholarlyteaching/effortful-retrieval/), co pozwoli na lepsze przyswojenie zdobytej wiedzy.\n",
        "\n",
        "Celem jest modyfikacja rozwiązania tak, aby kernel `saxpy` wykonywał się w około *200us* bez modyfikacji `N` (w środowisku Google Colab). **Rozwiązanie należy przesłać na michal.zimon@wat.edu.pl.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VozjuIbs_QVH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef8736d9-3098-4028-a75a-c5e8a3ea6712"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "c[0] = 5, c[1] = 5, c[2] = 5, c[3] = 5, c[4] = 5, \n",
            "c[4194299] = 5, c[4194300] = 5, c[4194301] = 5, c[4194302] = 5, c[4194303] = 5, \n"
          ]
        }
      ],
      "source": [
        "!nvcc -o saxpy 01-saxpy.cu -run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIlMn3uE_QVH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1c1009f-4fca-4bfc-dbf5-78386c58da82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: LBR backtrace method is not supported on this platform. DWARF backtrace method will be used.\n",
            "Collecting data...\n",
            "c[0] = 5, c[1] = 5, c[2] = 5, c[3] = 5, c[4] = 5, \n",
            "c[4194299] = 5, c[4194300] = 5, c[4194301] = 5, c[4194302] = 5, c[4194303] = 5, \n",
            "\n",
            "The target application terminated with signal 11 (SIGSEGV)\n",
            "Processing events...\n",
            "Capturing symbol files...\n",
            "Saving temporary \"/tmp/nsys-report-067c-2b01-3a82-fcd1.qdstrm\" file to disk...\n",
            "Creating final output files...\n",
            "\n",
            "Processing [==============================================================100%]\n",
            "Saved report file to \"/tmp/nsys-report-067c-2b01-3a82-fcd1.qdrep\"\n",
            "Exporting 4481 events: [==================================================100%]\n",
            "\n",
            "Exported successfully to\n",
            "/tmp/nsys-report-067c-2b01-3a82-fcd1.sqlite\n",
            "\n",
            "\n",
            "CUDA API Statistics:\n",
            "\n",
            " Time(%)  Total Time (ns)  Num Calls    Average      Minimum     Maximum            Name         \n",
            " -------  ---------------  ---------  ------------  ---------  -----------  ---------------------\n",
            "    96.6      260,284,465          3  86,761,488.3     24,590  260,224,514  cudaMallocManaged    \n",
            "     1.8        4,825,258          1   4,825,258.0  4,825,258    4,825,258  cudaDeviceSynchronize\n",
            "     1.0        2,764,660          3     921,553.3    889,057      954,629  cudaFree             \n",
            "     0.6        1,567,557          3     522,519.0     11,442    1,386,096  cudaMemPrefetchAsync \n",
            "     0.0           65,485          1      65,485.0     65,485       65,485  cudaLaunchKernel     \n",
            "\n",
            "\n",
            "\n",
            "CUDA Kernel Statistics:\n",
            "\n",
            " Time(%)  Total Time (ns)  Instances   Average   Minimum  Maximum           Name          \n",
            " -------  ---------------  ---------  ---------  -------  -------  -----------------------\n",
            "   100.0          199,199          1  199,199.0  199,199  199,199  saxpy(int*, int*, int*)\n",
            "\n",
            "\n",
            "\n",
            "CUDA Memory Operation Statistics (by time):\n",
            "\n",
            " Time(%)  Total Time (ns)  Operations   Average   Minimum  Maximum              Operation            \n",
            " -------  ---------------  ----------  ---------  -------  -------  ---------------------------------\n",
            "    99.6        4,285,045          24  178,543.5  174,207  196,064  [CUDA Unified Memory memcpy HtoD]\n",
            "     0.4           17,598           4    4,399.5    1,983    7,008  [CUDA Unified Memory memcpy DtoH]\n",
            "\n",
            "\n",
            "\n",
            "CUDA Memory Operation Statistics (by size in KiB):\n",
            "\n",
            "   Total     Operations   Average    Minimum    Maximum               Operation            \n",
            " ----------  ----------  ---------  ---------  ---------  ---------------------------------\n",
            " 49,152.000          24  2,048.000  2,048.000  2,048.000  [CUDA Unified Memory memcpy HtoD]\n",
            "    128.000           4     32.000      4.000     60.000  [CUDA Unified Memory memcpy DtoH]\n",
            "\n",
            "\n",
            "\n",
            "Operating System Runtime API Statistics:\n",
            "\n",
            " Time(%)  Total Time (ns)  Num Calls    Average     Minimum   Maximum            Name         \n",
            " -------  ---------------  ---------  ------------  -------  ----------  ---------------------\n",
            "    69.1      371,800,893         25  14,872,035.7    1,555  96,821,421  poll                 \n",
            "    22.0      118,515,180        668     177,417.9    1,087  18,038,774  ioctl                \n",
            "     8.4       45,237,603         16   2,827,350.2   28,445  20,636,475  sem_timedwait        \n",
            "     0.2          906,633         82      11,056.5    3,065      24,076  open64               \n",
            "     0.2          861,937          4     215,484.3   35,828     455,467  sem_wait             \n",
            "     0.0          268,159          5      53,631.8   37,825      76,874  pthread_create       \n",
            "     0.0          133,213         13      10,247.2    3,878      33,261  write                \n",
            "     0.0          130,890         25       5,235.6    1,645      17,394  fopen                \n",
            "     0.0          111,674         10      11,167.4    5,047      30,966  fgetc                \n",
            "     0.0           97,601          3      32,533.7   28,475      36,353  fgets                \n",
            "     0.0           54,380         15       3,625.3    1,077      21,678  fclose               \n",
            "     0.0           53,773          6       8,962.2    3,250      12,818  open                 \n",
            "     0.0           28,598          2      14,299.0    6,390      22,208  socket               \n",
            "     0.0           25,442         13       1,957.1    1,084       4,743  read                 \n",
            "     0.0           16,831          1      16,831.0   16,831      16,831  pthread_mutex_trylock\n",
            "     0.0           15,636          3       5,212.0    1,465       9,798  fread                \n",
            "     0.0           13,218          1      13,218.0   13,218      13,218  connect              \n",
            "     0.0           10,077          1      10,077.0   10,077      10,077  pipe2                \n",
            "     0.0            7,492          4       1,873.0    1,042       4,323  fcntl                \n",
            "     0.0            4,209          3       1,403.0    1,023       1,685  msync                \n",
            "     0.0            1,818          1       1,818.0    1,818       1,818  listen               \n",
            "     0.0            1,667          1       1,667.0    1,667       1,667  bind                 \n",
            "\n",
            "Report file moved to \"/content/report1.qdrep\"\n",
            "Report file moved to \"/content/report1.sqlite\"\n"
          ]
        }
      ],
      "source": [
        "!nsys profile --stats=true ./saxpy"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}